{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f693b1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T19:20:20.539259Z",
     "iopub.status.busy": "2022-12-17T19:20:20.538355Z",
     "iopub.status.idle": "2022-12-17T19:20:20.556879Z",
     "shell.execute_reply": "2022-12-17T19:20:20.555913Z"
    },
    "executionInfo": {
     "elapsed": 2637,
     "status": "ok",
     "timestamp": 1671270514960,
     "user": {
      "displayName": "Andrea Giuffrida",
      "userId": "01201743058689716524"
     },
     "user_tz": -60
    },
    "id": "UwhwoigqynhZ",
    "outputId": "42eb721f-eb4b-4fca-e3dd-83e4aeb3eaa9",
    "papermill": {
     "duration": 0.036189,
     "end_time": "2022-12-17T19:20:20.559987",
     "exception": false,
     "start_time": "2022-12-17T19:20:20.523798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/an2dlhw2originaldata/y_train.npy\n",
      "/kaggle/input/an2dlhw2originaldata/x_train.npy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "625162d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T19:20:20.587091Z",
     "iopub.status.busy": "2022-12-17T19:20:20.586263Z",
     "iopub.status.idle": "2022-12-17T19:20:20.592909Z",
     "shell.execute_reply": "2022-12-17T19:20:20.591894Z"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1671270514960,
     "user": {
      "displayName": "Andrea Giuffrida",
      "userId": "01201743058689716524"
     },
     "user_tz": -60
    },
    "id": "tmtVevhC12Ek",
    "outputId": "7968f163-66d7-4faa-c00d-c5a789d8c44e",
    "papermill": {
     "duration": 0.022587,
     "end_time": "2022-12-17T19:20:20.594992",
     "exception": false,
     "start_time": "2022-12-17T19:20:20.572405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "if os.path.exists(\"/kaggle/working/andrea\"):\n",
    "    shutil.rmtree(\"/kaggle/working/andrea\")\n",
    "\n",
    "# to remove a file\n",
    "if os.path.exists(\"/kaggle/working/model.png\"):\n",
    "    os.remove(\"/kaggle/working/model.png\")\n",
    "    \n",
    "# to create a folder\n",
    "import os\n",
    "directory = \"transformer_bagging\"\n",
    "parent_dir = \"/kaggle/working\"\n",
    "path = os.path.join(parent_dir, directory)\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fabc8110",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T19:20:20.619878Z",
     "iopub.status.busy": "2022-12-17T19:20:20.618948Z",
     "iopub.status.idle": "2022-12-17T19:20:20.626509Z",
     "shell.execute_reply": "2022-12-17T19:20:20.625044Z"
    },
    "papermill": {
     "duration": 0.022702,
     "end_time": "2022-12-17T19:20:20.629328",
     "exception": false,
     "start_time": "2022-12-17T19:20:20.606626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/transformer_bagging\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working/transformer_bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4aae571b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T19:20:20.654586Z",
     "iopub.status.busy": "2022-12-17T19:20:20.653615Z",
     "iopub.status.idle": "2022-12-17T19:20:33.612813Z",
     "shell.execute_reply": "2022-12-17T19:20:33.611393Z"
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1671270514961,
     "user": {
      "displayName": "Andrea Giuffrida",
      "userId": "01201743058689716524"
     },
     "user_tz": -60
    },
    "id": "n-k90K0j2Ffz",
    "outputId": "0c51fbe3-8d5b-46a0-a71a-a3473b5d082a",
    "papermill": {
     "duration": 12.974031,
     "end_time": "2022-12-17T19:20:33.615190",
     "exception": false,
     "start_time": "2022-12-17T19:20:20.641159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.4\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', size=16) \n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "from scipy.interpolate import interp1d\n",
    "import shutil\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e6f55fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T19:20:33.639988Z",
     "iopub.status.busy": "2022-12-17T19:20:33.638824Z",
     "iopub.status.idle": "2022-12-17T19:20:33.645029Z",
     "shell.execute_reply": "2022-12-17T19:20:33.644094Z"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1671270514961,
     "user": {
      "displayName": "Andrea Giuffrida",
      "userId": "01201743058689716524"
     },
     "user_tz": -60
    },
    "id": "n5ej6i4l2JKk",
    "papermill": {
     "duration": 0.020742,
     "end_time": "2022-12-17T19:20:33.647066",
     "exception": false,
     "start_time": "2022-12-17T19:20:33.626324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Random seed for reproducibility\n",
    "seed = 42\n",
    "\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "tf.compat.v1.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03f84c7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T19:20:33.670252Z",
     "iopub.status.busy": "2022-12-17T19:20:33.669959Z",
     "iopub.status.idle": "2022-12-17T19:20:33.675506Z",
     "shell.execute_reply": "2022-12-17T19:20:33.674663Z"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1671270514962,
     "user": {
      "displayName": "Andrea Giuffrida",
      "userId": "01201743058689716524"
     },
     "user_tz": -60
    },
    "id": "KiIPwujC9Ue5",
    "papermill": {
     "duration": 0.019312,
     "end_time": "2022-12-17T19:20:33.677401",
     "exception": false,
     "start_time": "2022-12-17T19:20:33.658089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalization = 'standard'\n",
    "axis = 2\n",
    "class_weighting = False\n",
    "oversampling = False\n",
    "noise = False\n",
    "bagging = True\n",
    "interpolate = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0016e87b",
   "metadata": {
    "id": "6W7HN96Y65ih",
    "papermill": {
     "duration": 0.010494,
     "end_time": "2022-12-17T19:20:33.698325",
     "exception": false,
     "start_time": "2022-12-17T19:20:33.687831",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e1698c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T19:20:33.720453Z",
     "iopub.status.busy": "2022-12-17T19:20:33.720181Z",
     "iopub.status.idle": "2022-12-17T19:20:33.814036Z",
     "shell.execute_reply": "2022-12-17T19:20:33.813105Z"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1671270514962,
     "user": {
      "displayName": "Andrea Giuffrida",
      "userId": "01201743058689716524"
     },
     "user_tz": -60
    },
    "id": "vNuMeLDf2Oaq",
    "papermill": {
     "duration": 0.10719,
     "end_time": "2022-12-17T19:20:33.816095",
     "exception": false,
     "start_time": "2022-12-17T19:20:33.708905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_file_path = \"/kaggle/input/an2dlhw2originaldata/x_train.npy\"\n",
    "y_file_path = \"/kaggle/input/an2dlhw2originaldata/y_train.npy\"\n",
    "\n",
    "X = np.load(x_file_path)\n",
    "y = np.load(y_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eaf38ef9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T19:20:33.840285Z",
     "iopub.status.busy": "2022-12-17T19:20:33.838719Z",
     "iopub.status.idle": "2022-12-17T19:20:33.844618Z",
     "shell.execute_reply": "2022-12-17T19:20:33.843632Z"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1671270514962,
     "user": {
      "displayName": "Andrea Giuffrida",
      "userId": "01201743058689716524"
     },
     "user_tz": -60
    },
    "id": "7u6FEVhuC9gr",
    "outputId": "4d54cbde-7862-4c7a-a0f8-9f50013fd329",
    "papermill": {
     "duration": 0.019611,
     "end_time": "2022-12-17T19:20:33.846943",
     "exception": false,
     "start_time": "2022-12-17T19:20:33.827332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if interpolate:    \n",
    "    x_axis = np.linspace(0, 36, num=36, endpoint=True)\n",
    "    intp = interp1d(x_axis, X, kind='cubic', axis=1)\n",
    "    x_new = np.linspace(0, 36, num=72, endpoint=True)\n",
    "    X = intp(x_new)\n",
    "    X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a436ecfb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T19:20:33.869665Z",
     "iopub.status.busy": "2022-12-17T19:20:33.869402Z",
     "iopub.status.idle": "2022-12-17T19:20:33.882312Z",
     "shell.execute_reply": "2022-12-17T19:20:33.881309Z"
    },
    "executionInfo": {
     "elapsed": 420,
     "status": "ok",
     "timestamp": 1671270515360,
     "user": {
      "displayName": "Andrea Giuffrida",
      "userId": "01201743058689716524"
     },
     "user_tz": -60
    },
    "id": "fnfDuJ5F3biy",
    "outputId": "7974b8ef-cd1b-4e52-adb7-9480ad6058b0",
    "papermill": {
     "duration": 0.027142,
     "end_time": "2022-12-17T19:20:33.884793",
     "exception": false,
     "start_time": "2022-12-17T19:20:33.857651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1943, 36, 6), (1943,), (486, 36, 6), (486,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "n_dimensions = X_train.shape[2]\n",
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bb68d9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T19:20:33.907654Z",
     "iopub.status.busy": "2022-12-17T19:20:33.907366Z",
     "iopub.status.idle": "2022-12-17T19:20:33.911785Z",
     "shell.execute_reply": "2022-12-17T19:20:33.910846Z"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1671270515361,
     "user": {
      "displayName": "Andrea Giuffrida",
      "userId": "01201743058689716524"
     },
     "user_tz": -60
    },
    "id": "SNX4WLvstRxU",
    "papermill": {
     "duration": 0.018339,
     "end_time": "2022-12-17T19:20:33.913895",
     "exception": false,
     "start_time": "2022-12-17T19:20:33.895556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    \"Wish\",\n",
    "    \"Another\",\n",
    "    \"Comfortably\",\n",
    "    \"Money\",\n",
    "    \"Breathe\",\n",
    "    \"Time\",\n",
    "    \"Brain\",\n",
    "    \"Echoes\",\n",
    "    \"Wearing\",\n",
    "    \"Sorrow\",\n",
    "    \"Hey\",\n",
    "    \"Shine\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6892b1fd",
   "metadata": {
    "id": "G837_K5R7Bdh",
    "papermill": {
     "duration": 0.010629,
     "end_time": "2022-12-17T19:20:33.935291",
     "exception": false,
     "start_time": "2022-12-17T19:20:33.924662",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "407d1f57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T19:20:33.958196Z",
     "iopub.status.busy": "2022-12-17T19:20:33.957930Z",
     "iopub.status.idle": "2022-12-17T19:20:33.967497Z",
     "shell.execute_reply": "2022-12-17T19:20:33.966620Z"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1671270515361,
     "user": {
      "displayName": "Andrea Giuffrida",
      "userId": "01201743058689716524"
     },
     "user_tz": -60
    },
    "id": "OOGCSx2B_9Ui",
    "papermill": {
     "duration": 0.023318,
     "end_time": "2022-12-17T19:20:33.969577",
     "exception": false,
     "start_time": "2022-12-17T19:20:33.946259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize(X_train, axis, norm_type='no_norm'):\n",
    "  axs = [0,1,2]\n",
    "  axs.remove(axis)\n",
    "  axs=tuple(axs)\n",
    "\n",
    "  means = np.mean(X_train, axis=axs)\n",
    "  stds = np.std(X_train, axis=axs)\n",
    "  mins = np.min(X_train, axis=axs)\n",
    "  maxs = np.max(X_train, axis=axs)\n",
    "\n",
    "  params = {\n",
    "      \"means\": means,\n",
    "      \"stds\": stds,\n",
    "      \"mins\": mins,\n",
    "      \"maxs\": maxs\n",
    "  }\n",
    "  \n",
    "  if norm_type=='standard':\n",
    "    X_std_train = []\n",
    "    \n",
    "    for i in range(X_train.shape[axis]):\n",
    "      data = np.take(X_train, i, axis=axis)\n",
    "      data = (data - means[i]) / stds[i]\n",
    "      X_std_train.append(data)\n",
    "\n",
    "    X_std_train = tuple(X_std_train)\n",
    "    X_std_train = np.stack(X_std_train, axis=axis)\n",
    "\n",
    "    return X_std_train, params\n",
    "\n",
    "\n",
    "  elif norm_type=='minmax':\n",
    "    X_norm_train = []\n",
    "    \n",
    "    for i in range(X_train.shape[axis]):\n",
    "      data = np.take(X_train, i, axis=axis)\n",
    "      data = (data - mins[i]) / (maxs[i] - mins[i])\n",
    "      X_norm_train.append(data)\n",
    "\n",
    "    X_norm_train = tuple(X_norm_train)\n",
    "    X_norm_train = np.stack(X_norm_train, axis=axis)\n",
    "\n",
    "    return X_norm_train, params\n",
    "\n",
    "  else:\n",
    "    return X_train, params\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "030e5f05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T19:20:33.992323Z",
     "iopub.status.busy": "2022-12-17T19:20:33.991896Z",
     "iopub.status.idle": "2022-12-17T19:20:33.999643Z",
     "shell.execute_reply": "2022-12-17T19:20:33.998703Z"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1671270515362,
     "user": {
      "displayName": "Andrea Giuffrida",
      "userId": "01201743058689716524"
     },
     "user_tz": -60
    },
    "id": "FSL8OzXZRlYC",
    "papermill": {
     "duration": 0.021289,
     "end_time": "2022-12-17T19:20:34.001589",
     "exception": false,
     "start_time": "2022-12-17T19:20:33.980300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_test(X, params, axis, norm_type='no_norm'):\n",
    "  \n",
    "  if norm_type=='standard':\n",
    "    X_std_val = []\n",
    "\n",
    "    means = params[\"means\"]\n",
    "    stds = params[\"stds\"]\n",
    "    mins = params[\"mins\"]\n",
    "    maxs = params[\"maxs\"]\n",
    "\n",
    "    for i in range(X.shape[axis]):\n",
    "      data = np.take(X, i, axis=axis)\n",
    "      data = (data - means[i]) / stds[i]\n",
    "      X_std_val.append(data)\n",
    "\n",
    "    X_std_val = tuple(X_std_val)\n",
    "    X_std_val = np.stack(X_std_val, axis=axis)\n",
    "\n",
    "    return X_std_val\n",
    "\n",
    "  elif norm_type=='minmax':\n",
    "    X_norm_val = []\n",
    "    \n",
    "    for i in range(X.shape[axis]):\n",
    "      data = np.take(X, i, axis=axis)\n",
    "      data = (data - mins[i]) / (maxs[i] - min)\n",
    "      X_norm_val.append(data)\n",
    "\n",
    "    X_norm_val = tuple(X_norm_val)\n",
    "    X_norm_val = np.stack(X_norm_val, axis=axis)\n",
    "\n",
    "    return X_norm_val\n",
    "\n",
    "  else:\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe8f6f66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T19:20:34.027200Z",
     "iopub.status.busy": "2022-12-17T19:20:34.026441Z",
     "iopub.status.idle": "2022-12-17T19:20:34.059910Z",
     "shell.execute_reply": "2022-12-17T19:20:34.059001Z"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1671270515362,
     "user": {
      "displayName": "Andrea Giuffrida",
      "userId": "01201743058689716524"
     },
     "user_tz": -60
    },
    "id": "3XlGDA5_GiCb",
    "papermill": {
     "duration": 0.048531,
     "end_time": "2022-12-17T19:20:34.062073",
     "exception": false,
     "start_time": "2022-12-17T19:20:34.013542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_no_norm = X_train\n",
    "X_train, p = normalize(X_train, axis, norm_type=normalization)\n",
    "X_val = normalize_test(X_val, p, axis, norm_type=normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b8c48c",
   "metadata": {
    "id": "aC5bVFqz7JG9",
    "papermill": {
     "duration": 0.011189,
     "end_time": "2022-12-17T19:20:34.084696",
     "exception": false,
     "start_time": "2022-12-17T19:20:34.073507",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Comput class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c781be8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T19:20:34.108805Z",
     "iopub.status.busy": "2022-12-17T19:20:34.108511Z",
     "iopub.status.idle": "2022-12-17T19:20:34.114086Z",
     "shell.execute_reply": "2022-12-17T19:20:34.113030Z"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1671270515363,
     "user": {
      "displayName": "Andrea Giuffrida",
      "userId": "01201743058689716524"
     },
     "user_tz": -60
    },
    "id": "Oibh_HvTWT3S",
    "papermill": {
     "duration": 0.019976,
     "end_time": "2022-12-17T19:20:34.116229",
     "exception": false,
     "start_time": "2022-12-17T19:20:34.096253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if class_weighting:\n",
    "  class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y)\n",
    "\n",
    "  fig = plt.figure(figsize=(21, 5))\n",
    "  plt.bar(np.arange(12), class_weights, width=1, edgecolor=\"white\", tick_label=list(label_mapping))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55bb7319",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T19:20:34.140145Z",
     "iopub.status.busy": "2022-12-17T19:20:34.139840Z",
     "iopub.status.idle": "2022-12-17T19:20:34.144121Z",
     "shell.execute_reply": "2022-12-17T19:20:34.143120Z"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1671270515363,
     "user": {
      "displayName": "Andrea Giuffrida",
      "userId": "01201743058689716524"
     },
     "user_tz": -60
    },
    "id": "-KK4glI5wgLU",
    "papermill": {
     "duration": 0.018285,
     "end_time": "2022-12-17T19:20:34.146092",
     "exception": false,
     "start_time": "2022-12-17T19:20:34.127807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if class_weighting:\n",
    "  class_weights = dict(zip(np.arange(12), class_weights))\n",
    "  class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3623e2e5",
   "metadata": {
    "id": "T3Ne3mUq7OWL",
    "papermill": {
     "duration": 0.011025,
     "end_time": "2022-12-17T19:20:34.168176",
     "exception": false,
     "start_time": "2022-12-17T19:20:34.157151",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Random oversampling and undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7344e65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T19:20:34.192177Z",
     "iopub.status.busy": "2022-12-17T19:20:34.191363Z",
     "iopub.status.idle": "2022-12-17T19:20:34.198815Z",
     "shell.execute_reply": "2022-12-17T19:20:34.197961Z"
    },
    "executionInfo": {
     "elapsed": 760,
     "status": "ok",
     "timestamp": 1671270516112,
     "user": {
      "displayName": "Andrea Giuffrida",
      "userId": "01201743058689716524"
     },
     "user_tz": -60
    },
    "id": "eGve4BFmzciQ",
    "papermill": {
     "duration": 0.021346,
     "end_time": "2022-12-17T19:20:34.200826",
     "exception": false,
     "start_time": "2022-12-17T19:20:34.179480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if oversampling:\n",
    "  ros = RandomOverSampler(random_state=seed)\n",
    "  smote = SMOTE(random_state=seed)\n",
    "  adasyn = ADASYN(random_state=seed)\n",
    "  smoteenn = SMOTEENN(random_state=seed)\n",
    "  smote_tomek = SMOTETomek(random_state=seed)\n",
    "\n",
    "  if noise:\n",
    "    X_train = X_train_no_norm\n",
    "\n",
    "  X1 = []\n",
    "\n",
    "  for dim in range(n_dimensions):\n",
    "    X_dim = X_train[:,:,dim]\n",
    "    X1.append(X_dim)\n",
    "\n",
    "  X1 = np.concatenate(X1, axis=1)\n",
    "  X_ros, y_ros = adasyn.fit_resample(X1, y_train)\n",
    "  X_ros = np.reshape(X_ros, (X_ros.shape[0], X_train.shape[1], X_train.shape[2]), order='F')\n",
    "  X_train, y_train = X_ros, y_ros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec9c37db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T19:20:34.224454Z",
     "iopub.status.busy": "2022-12-17T19:20:34.223500Z",
     "iopub.status.idle": "2022-12-17T19:20:34.228909Z",
     "shell.execute_reply": "2022-12-17T19:20:34.228062Z"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1671270516112,
     "user": {
      "displayName": "Andrea Giuffrida",
      "userId": "01201743058689716524"
     },
     "user_tz": -60
    },
    "id": "2Dj6bi_E6nQt",
    "outputId": "1c19d45a-9d38-4c88-ce08-bdc093e8d7b9",
    "papermill": {
     "duration": 0.019216,
     "end_time": "2022-12-17T19:20:34.230898",
     "exception": false,
     "start_time": "2022-12-17T19:20:34.211682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if oversampling:\n",
    "  plt.bar(np.arange(12), np.argmax(y_ros), width=1, edgecolor=\"white\", tick_label=list(np.arange(12)))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2894707f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T19:20:34.255225Z",
     "iopub.status.busy": "2022-12-17T19:20:34.254381Z",
     "iopub.status.idle": "2022-12-17T19:20:34.264732Z",
     "shell.execute_reply": "2022-12-17T19:20:34.263784Z"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1671270516112,
     "user": {
      "displayName": "Andrea Giuffrida",
      "userId": "01201743058689716524"
     },
     "user_tz": -60
    },
    "id": "2hBm94TJeJLg",
    "papermill": {
     "duration": 0.024461,
     "end_time": "2022-12-17T19:20:34.266636",
     "exception": false,
     "start_time": "2022-12-17T19:20:34.242175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AWGNTrain(tfk.utils.Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x_original, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.epoch = 0\n",
    "\n",
    "        noise = np.random.normal(0,1, size=self.x_original.shape)\n",
    "        self.x = self.x_original + noise\n",
    "        self.x, _ = normalize(self.x, axis, norm_type=normalization)\n",
    "\n",
    "        x_norm, _ = normalize(self.x_original, axis=2, norm_type='standard')\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        return np.array(batch_x), np.array(batch_y)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        noise = np.random.normal(0,1, size=self.x_original.shape)\n",
    "        self.x = self.x_original + noise\n",
    "        self.x, _ = normalize(self.x, axis, norm_type=normalization)\n",
    "\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a078e7",
   "metadata": {
    "id": "lmgVqmDvPUhA",
    "papermill": {
     "duration": 0.010475,
     "end_time": "2022-12-17T19:20:34.288014",
     "exception": false,
     "start_time": "2022-12-17T19:20:34.277539",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# To categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b77d337f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T19:20:34.310717Z",
     "iopub.status.busy": "2022-12-17T19:20:34.310101Z",
     "iopub.status.idle": "2022-12-17T19:20:34.316858Z",
     "shell.execute_reply": "2022-12-17T19:20:34.315916Z"
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1671270516113,
     "user": {
      "displayName": "Andrea Giuffrida",
      "userId": "01201743058689716524"
     },
     "user_tz": -60
    },
    "id": "uNrIag6w4TE8",
    "outputId": "6227a414-c63b-4308-df98-85ee1b915c57",
    "papermill": {
     "duration": 0.020254,
     "end_time": "2022-12-17T19:20:34.318838",
     "exception": false,
     "start_time": "2022-12-17T19:20:34.298584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1943, 12), (486, 12))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = tfk.utils.to_categorical(y_train)\n",
    "y_val = tfk.utils.to_categorical(y_val)\n",
    "y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77a6325a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T19:20:34.341686Z",
     "iopub.status.busy": "2022-12-17T19:20:34.340867Z",
     "iopub.status.idle": "2022-12-17T19:20:34.347169Z",
     "shell.execute_reply": "2022-12-17T19:20:34.346233Z"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1671270516113,
     "user": {
      "displayName": "Andrea Giuffrida",
      "userId": "01201743058689716524"
     },
     "user_tz": -60
    },
    "id": "_P7otpOk5_lg",
    "outputId": "1af9f588-796e-4b14-98ef-dadf6d4eb5f0",
    "papermill": {
     "duration": 0.019613,
     "end_time": "2022-12-17T19:20:34.349023",
     "exception": false,
     "start_time": "2022-12-17T19:20:34.329410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1943, 36, 6), (1943, 12))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf5e2e8",
   "metadata": {
    "id": "UGrY1hV97cG1",
    "papermill": {
     "duration": 0.010278,
     "end_time": "2022-12-17T19:20:34.369756",
     "exception": false,
     "start_time": "2022-12-17T19:20:34.359478",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utility function and classes definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fcfe8d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T19:20:34.393539Z",
     "iopub.status.busy": "2022-12-17T19:20:34.392729Z",
     "iopub.status.idle": "2022-12-17T19:20:34.401857Z",
     "shell.execute_reply": "2022-12-17T19:20:34.400994Z"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1671270516114,
     "user": {
      "displayName": "Andrea Giuffrida",
      "userId": "01201743058689716524"
     },
     "user_tz": -60
    },
    "id": "PDXHXweV1yKA",
    "papermill": {
     "duration": 0.0233,
     "end_time": "2022-12-17T19:20:34.403839",
     "exception": false,
     "start_time": "2022-12-17T19:20:34.380539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Utility function to create folders and callbacks for training\n",
    "from datetime import datetime\n",
    "\n",
    "def create_folders_and_callbacks(model_name, experiments_name):\n",
    "\n",
    "  exps_dir = os.path.join(experiments_name)\n",
    "  if not os.path.exists(exps_dir):\n",
    "      os.makedirs(exps_dir)\n",
    "\n",
    "  now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "\n",
    "  exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
    "  if not os.path.exists(exp_dir):\n",
    "      os.makedirs(exp_dir)\n",
    "      \n",
    "  callbacks = []\n",
    "\n",
    "  # Model checkpoint\n",
    "  # ----------------\n",
    "  ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
    "  if not os.path.exists(ckpt_dir):\n",
    "      os.makedirs(ckpt_dir)\n",
    "\n",
    "  ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp.ckpt'), \n",
    "                                                     save_weights_only=True, # True to save only weights\n",
    "                                                     save_best_only=False) # True to save only the best epoch \n",
    "  callbacks.append(ckpt_callback)\n",
    "\n",
    "  # Visualize Learning on Tensorboard\n",
    "  # ---------------------------------\n",
    "  tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
    "  if not os.path.exists(tb_dir):\n",
    "      os.makedirs(tb_dir)\n",
    "      \n",
    "  # By default shows losses and metrics for both training and validation\n",
    "  tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir, \n",
    "                                               profile_batch=0,\n",
    "                                               histogram_freq=1)  # if > 0 (epochs) shows weights histograms\n",
    "  callbacks.append(tb_callback)\n",
    "\n",
    "  return callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f309d2",
   "metadata": {
    "id": "jaCbGpAT7oM3",
    "papermill": {
     "duration": 0.010866,
     "end_time": "2022-12-17T19:20:34.425852",
     "exception": false,
     "start_time": "2022-12-17T19:20:34.414986",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model building function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5fea269",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T19:20:34.450569Z",
     "iopub.status.busy": "2022-12-17T19:20:34.449598Z",
     "iopub.status.idle": "2022-12-17T19:20:34.454465Z",
     "shell.execute_reply": "2022-12-17T19:20:34.453537Z"
    },
    "papermill": {
     "duration": 0.019527,
     "end_time": "2022-12-17T19:20:34.456595",
     "exception": false,
     "start_time": "2022-12-17T19:20:34.437068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"Conv1D_Interpolation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85448251",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T19:20:34.481218Z",
     "iopub.status.busy": "2022-12-17T19:20:34.480389Z",
     "iopub.status.idle": "2022-12-17T19:20:34.492835Z",
     "shell.execute_reply": "2022-12-17T19:20:34.491882Z"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1671270516114,
     "user": {
      "displayName": "Andrea Giuffrida",
      "userId": "01201743058689716524"
     },
     "user_tz": -60
    },
    "id": "rdf8sESK54il",
    "papermill": {
     "duration": 0.027039,
     "end_time": "2022-12-17T19:20:34.495148",
     "exception": false,
     "start_time": "2022-12-17T19:20:34.468109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_classifier(input_shape=X_train.shape[1:], classes=y.shape[-1], model_name=model_name, lr=0.001):\n",
    "    # Build the neural network layer by layer\n",
    "\n",
    "    input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
    "    cnn = tfkl.Conv1D(300,3,padding='same',activation='relu')(input_layer) # we will have the same samples in the next layer, we dont loose the temporality\n",
    "    cnn = tfkl.Conv1D(300,3,padding='same',activation='relu')(cnn)\n",
    "    cnn = tfkl.MaxPooling1D()(cnn)\n",
    "    cnn = tfkl.Conv1D(300,3,padding='same',activation='relu')(cnn)\n",
    "    cnn = tfkl.Conv1D(300,3,padding='same',activation='relu')(cnn)\n",
    "    cnn = tfkl.MaxPooling1D()(cnn)\n",
    "    dropout = tfkl.Dropout(.4, seed=seed)(cnn)\n",
    "    cnn = tfkl.Conv1D(300,3,padding='same',activation='relu')(dropout)\n",
    "    cnn = tfkl.Conv1D(300,3,padding='same',activation='relu')(cnn)\n",
    "    cnn = tfkl.MaxPooling1D()(cnn)\n",
    "    cnn = tfkl.Conv1D(300,3,padding='same',activation='relu')(cnn)\n",
    "    cnn = tfkl.Conv1D(300,3,padding='same',activation='relu')(cnn)\n",
    "    cnn = tfkl.MaxPooling1D()(cnn)\n",
    "    dropout2 = tfkl.Dropout(.4, seed=seed)(cnn)\n",
    "\n",
    "    att = tf.keras.layers.MultiHeadAttention(num_heads=18, key_dim=36)(input_layer, dropout2)\n",
    "\n",
    "    gap = tfkl.GlobalAveragePooling1D()(att)\n",
    "\n",
    "    # Classifier\n",
    "    classifier = tfkl.Dense(300, activation='relu', kernel_regularizer=tfk.regularizers.L1L2(l1=1e-4, l2=1e-3))(gap)\n",
    "    dropout = tfkl.Dropout(.4, seed=seed)(classifier)\n",
    "    output_layer = tfkl.Dense(classes, activation='softmax')(dropout)\n",
    "\n",
    "    # Connect input and output through the Model class\n",
    "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name=model_name)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(lr), metrics='accuracy')\n",
    "\n",
    "    # Return the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057669f9",
   "metadata": {
    "id": "DG0EFCN77hhx",
    "papermill": {
     "duration": 0.011182,
     "end_time": "2022-12-17T19:20:34.517785",
     "exception": false,
     "start_time": "2022-12-17T19:20:34.506603",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Parameters for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4cea0a19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T19:20:34.542233Z",
     "iopub.status.busy": "2022-12-17T19:20:34.541314Z",
     "iopub.status.idle": "2022-12-17T19:20:34.547416Z",
     "shell.execute_reply": "2022-12-17T19:20:34.546538Z"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1671270516114,
     "user": {
      "displayName": "Andrea Giuffrida",
      "userId": "01201743058689716524"
     },
     "user_tz": -60
    },
    "id": "XUpE4LS95t-b",
    "papermill": {
     "duration": 0.020263,
     "end_time": "2022-12-17T19:20:34.549440",
     "exception": false,
     "start_time": "2022-12-17T19:20:34.529177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"Conv1D_transformer_bagging\"\n",
    "experiments_name = \"Conv1D_transformer_bagging\"\n",
    "\n",
    "n_splits = 20\n",
    "\n",
    "input_shape = X_train.shape[1:]\n",
    "classes = y_train.shape[-1]\n",
    "batch_size = 128\n",
    "epochs = 200\n",
    "\n",
    "patience1 = 20\n",
    "patience_plateau = 5\n",
    "min_lr = 1e-5\n",
    "lr_factor = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3b4914",
   "metadata": {
    "id": "_5s1kBgrYN5R",
    "papermill": {
     "duration": 0.011921,
     "end_time": "2022-12-17T19:20:34.572741",
     "exception": false,
     "start_time": "2022-12-17T19:20:34.560820",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Bagging class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "60dbbeaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T19:20:34.597656Z",
     "iopub.status.busy": "2022-12-17T19:20:34.596857Z",
     "iopub.status.idle": "2022-12-17T19:20:34.615783Z",
     "shell.execute_reply": "2022-12-17T19:20:34.614917Z"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1671270516115,
     "user": {
      "displayName": "Andrea Giuffrida",
      "userId": "01201743058689716524"
     },
     "user_tz": -60
    },
    "id": "lQ8BndGTBGBk",
    "papermill": {
     "duration": 0.033307,
     "end_time": "2022-12-17T19:20:34.617849",
     "exception": false,
     "start_time": "2022-12-17T19:20:34.584542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BaggingModel(tfk.Model):\n",
    "  def __init__(self, n_splits, inp, classes, model_name):\n",
    "    super().__init__()\n",
    "    self.n_splits = n_splits\n",
    "    self.inp = inp\n",
    "    self.classes = classes\n",
    "    self.model_name = model_name\n",
    "    self.models = []\n",
    "    for i in range(self.n_splits):\n",
    "      name = model_name + str(i)\n",
    "      self.models.append(build_classifier(self.inp, self.classes, name))\n",
    "\n",
    "  def fit(self,\n",
    "    x=None,\n",
    "    y=None,\n",
    "    batch_size=None,\n",
    "    epochs=1,\n",
    "    verbose='auto',\n",
    "    callbacks=None,\n",
    "    validation_split=0.0,\n",
    "    validation_data=None,\n",
    "    shuffle=True,\n",
    "    class_weight=None,\n",
    "    sample_weight=None,\n",
    "    initial_epoch=0,\n",
    "    steps_per_epoch=None,\n",
    "    validation_steps=None,\n",
    "    validation_batch_size=None,\n",
    "    validation_freq=1,\n",
    "    max_queue_size=10,\n",
    "    workers=1,\n",
    "    use_multiprocessing=False):\n",
    "\n",
    "\n",
    "    for i, model in enumerate(self.models):  \n",
    "      # multiple train-test splits\n",
    "      scores = []\n",
    "      n_samples = x.shape[0]\n",
    "\n",
    "      # select indexes\n",
    "      ix = [i for i in range(n_samples)]\n",
    "      train_ix = resample(ix, replace=True, n_samples=n_samples)\n",
    "      test_ix = [x for x in ix if x not in train_ix]\n",
    "\n",
    "      # select data\n",
    "      X_train, y_train = tf.gather(x, indices=train_ix), y[train_ix]\n",
    "      X_test, y_test = tf.gather(x, indices=test_ix), y[test_ix]\n",
    "\n",
    "      # train model\n",
    "      print(\"Training of model \", str(i))\n",
    "      history = model.fit(\n",
    "        x = X_train,\n",
    "        y = y_train,\n",
    "        batch_size = batch_size,\n",
    "        epochs = epochs,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks = callbacks,\n",
    "        shuffle = shuffle\n",
    "      ).history\n",
    "      print()\n",
    "\n",
    "      score = model.evaluate(X_test, y_test)\n",
    "      scores.append(score)\n",
    "    \n",
    "    print(\"Validation scores for each model:\")\n",
    "\n",
    "    for i, score in enumerate(scores):\n",
    "      print(\"Score of model \", str(i))\n",
    "      print(score)\n",
    "      print()\n",
    "        \n",
    "\n",
    "\n",
    "  def predict(self, x):\n",
    "    # make predictions\n",
    "    yhats = [model.predict(x) for model in self.models]\n",
    "    \n",
    "    yhats = np.array(yhats)\n",
    "   \n",
    "    # sum across ensemble members\n",
    "    summed = np.sum(yhats, axis=0)\n",
    "\n",
    "    # argmax across classes\n",
    "    result = np.argmax(summed, axis=1)\n",
    "\n",
    "    result = tfk.utils.to_categorical(result)\n",
    "    \n",
    "    # return the result\n",
    "    return result\n",
    "    pass\n",
    "\n",
    "  def save(self,\n",
    "      filepath,\n",
    "      overwrite=True,\n",
    "      include_optimizer=True,\n",
    "      save_format=None,\n",
    "      signatures=None,\n",
    "      options=None,\n",
    "      save_traces=True\n",
    "  ):\n",
    "\n",
    "    parent_dir = filepath\n",
    "    if os.path.exists(parent_dir):\n",
    "            shutil.rmtree(parent_dir)\n",
    "    os.mkdir(parent_dir)\n",
    "\n",
    "    for i, model in enumerate(self.models):\n",
    "      directory = self.model_name + str(i)\n",
    "      path = os.path.join(parent_dir, directory)\n",
    "      if os.path.exists(path):\n",
    "          shutil.rmtree(path)\n",
    "      os.mkdir(path)\n",
    "      model.save(path)\n",
    "\n",
    "  def load(self, filepath):\n",
    "    parent_dir = filepath\n",
    "    for i in range(self.n_splits):\n",
    "      directory = self.model_name + str(i)\n",
    "      path = os.path.join(parent_dir, directory)\n",
    "      if os.path.exists(path):\n",
    "        self.models[i] = tfk.models.load_model(path)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c6db79",
   "metadata": {
    "id": "Qk7uYg437lM8",
    "papermill": {
     "duration": 0.01126,
     "end_time": "2022-12-17T19:20:34.640593",
     "exception": false,
     "start_time": "2022-12-17T19:20:34.629333",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44382aa0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T19:20:34.664177Z",
     "iopub.status.busy": "2022-12-17T19:20:34.663857Z",
     "iopub.status.idle": "2022-12-17T19:20:42.848694Z",
     "shell.execute_reply": "2022-12-17T19:20:42.847730Z"
    },
    "executionInfo": {
     "elapsed": 420,
     "status": "ok",
     "timestamp": 1671270516511,
     "user": {
      "displayName": "Andrea Giuffrida",
      "userId": "01201743058689716524"
     },
     "user_tz": -60
    },
    "id": "22L0ojTk7XrA",
    "outputId": "392b9089-a426-4cd4-feba-62b6fc757d87",
    "papermill": {
     "duration": 8.199201,
     "end_time": "2022-12-17T19:20:42.851009",
     "exception": false,
     "start_time": "2022-12-17T19:20:34.651808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-17 19:20:34.825360: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-17 19:20:34.826364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-17 19:20:35.154425: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-17 19:20:35.155360: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-17 19:20:35.156249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-17 19:20:35.157037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-17 19:20:35.158854: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-17 19:20:35.429148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-17 19:20:35.430112: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-17 19:20:35.430861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-17 19:20:35.431642: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-17 19:20:35.432377: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-17 19:20:35.433075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-17 19:20:39.792745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-17 19:20:39.793742: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-17 19:20:39.794557: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-17 19:20:39.795344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-17 19:20:39.796091: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-17 19:20:39.796754: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13789 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "2022-12-17 19:20:39.801360: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-17 19:20:39.802020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13789 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "if not bagging:\n",
    "  model = build_classifier(input_shape, classes, model_name)\n",
    "  model.summary()\n",
    "else:\n",
    "  model = BaggingModel(n_splits, input_shape, classes, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a68d3e9",
   "metadata": {
    "id": "GR6aytkW7zWM",
    "papermill": {
     "duration": 0.010708,
     "end_time": "2022-12-17T19:20:42.872970",
     "exception": false,
     "start_time": "2022-12-17T19:20:42.862262",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d1904cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T19:20:42.895925Z",
     "iopub.status.busy": "2022-12-17T19:20:42.895618Z",
     "iopub.status.idle": "2022-12-17T19:20:42.901150Z",
     "shell.execute_reply": "2022-12-17T19:20:42.900219Z"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1671270516511,
     "user": {
      "displayName": "Andrea Giuffrida",
      "userId": "01201743058689716524"
     },
     "user_tz": -60
    },
    "id": "nT65XyW2y1sE",
    "outputId": "6fe544fd-d3e5-4901-ac1a-0044026fcf32",
    "papermill": {
     "duration": 0.019452,
     "end_time": "2022-12-17T19:20:42.903359",
     "exception": false,
     "start_time": "2022-12-17T19:20:42.883907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'interpolation'\n",
      "/kaggle/working/transformer_bagging\n"
     ]
    }
   ],
   "source": [
    "%cd interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e3c393f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T19:20:42.926703Z",
     "iopub.status.busy": "2022-12-17T19:20:42.926441Z",
     "iopub.status.idle": "2022-12-17T19:50:13.968514Z",
     "shell.execute_reply": "2022-12-17T19:50:13.967517Z"
    },
    "executionInfo": {
     "elapsed": 37009,
     "status": "error",
     "timestamp": 1671270553511,
     "user": {
      "displayName": "Andrea Giuffrida",
      "userId": "01201743058689716524"
     },
     "user_tz": -60
    },
    "id": "bHCTEUdwjJIN",
    "outputId": "be5c4766-c499-4bcb-81c6-ea5d3f89e295",
    "papermill": {
     "duration": 1771.056133,
     "end_time": "2022-12-17T19:50:13.970656",
     "exception": false,
     "start_time": "2022-12-17T19:20:42.914523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training of model  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-17 19:20:43.105997: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-17 19:20:48.500173: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 16s 121ms/step - loss: 2.3863 - accuracy: 0.3114 - val_loss: 2.2506 - val_accuracy: 0.3252\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 2.1197 - accuracy: 0.3314 - val_loss: 2.0428 - val_accuracy: 0.3374\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 2.0274 - accuracy: 0.3484 - val_loss: 2.0129 - val_accuracy: 0.3455\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.9448 - accuracy: 0.3716 - val_loss: 1.9399 - val_accuracy: 0.3699\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.8703 - accuracy: 0.3958 - val_loss: 2.0018 - val_accuracy: 0.3713\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.9176 - accuracy: 0.3685 - val_loss: 1.8935 - val_accuracy: 0.3753\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.8242 - accuracy: 0.4004 - val_loss: 1.9207 - val_accuracy: 0.3469\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.7886 - accuracy: 0.4102 - val_loss: 1.7941 - val_accuracy: 0.3957\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.7852 - accuracy: 0.4112 - val_loss: 1.7408 - val_accuracy: 0.4160\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.6886 - accuracy: 0.4210 - val_loss: 1.9188 - val_accuracy: 0.3916\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 1.7132 - accuracy: 0.4251 - val_loss: 1.7581 - val_accuracy: 0.3997\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.6283 - accuracy: 0.4380 - val_loss: 1.5575 - val_accuracy: 0.4444\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.6923 - accuracy: 0.4256 - val_loss: 1.6592 - val_accuracy: 0.4268\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.5701 - accuracy: 0.4699 - val_loss: 1.5713 - val_accuracy: 0.4621\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.4339 - accuracy: 0.5090 - val_loss: 1.5411 - val_accuracy: 0.5217\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.3835 - accuracy: 0.5162 - val_loss: 1.5502 - val_accuracy: 0.4932\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.3314 - accuracy: 0.5450 - val_loss: 1.5558 - val_accuracy: 0.5379\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3413 - accuracy: 0.5481 - val_loss: 1.4745 - val_accuracy: 0.5095\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.2967 - accuracy: 0.5502 - val_loss: 1.3783 - val_accuracy: 0.5447\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.1803 - accuracy: 0.5955 - val_loss: 1.5477 - val_accuracy: 0.5854\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.1831 - accuracy: 0.6027 - val_loss: 1.2612 - val_accuracy: 0.5949\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.1936 - accuracy: 0.6099 - val_loss: 1.3316 - val_accuracy: 0.5650\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1585 - accuracy: 0.5975 - val_loss: 1.3332 - val_accuracy: 0.5474\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.0301 - accuracy: 0.6531 - val_loss: 1.2254 - val_accuracy: 0.5854\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0343 - accuracy: 0.6670 - val_loss: 1.1913 - val_accuracy: 0.6070\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0824 - accuracy: 0.6428 - val_loss: 1.4266 - val_accuracy: 0.5732\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.0240 - accuracy: 0.6639 - val_loss: 1.3492 - val_accuracy: 0.5962\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.9518 - accuracy: 0.6794 - val_loss: 1.3296 - val_accuracy: 0.5976\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.9252 - accuracy: 0.7010 - val_loss: 1.2394 - val_accuracy: 0.5949\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.8518 - accuracy: 0.7133 - val_loss: 1.3070 - val_accuracy: 0.6016\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8184 - accuracy: 0.7458 - val_loss: 1.4144 - val_accuracy: 0.6192\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.7489 - accuracy: 0.7535 - val_loss: 1.3875 - val_accuracy: 0.6111\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.7186 - accuracy: 0.7653 - val_loss: 1.3291 - val_accuracy: 0.5813\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.7439 - accuracy: 0.7560 - val_loss: 1.3352 - val_accuracy: 0.5894\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.7266 - accuracy: 0.7530 - val_loss: 1.4755 - val_accuracy: 0.6070\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.7585 - accuracy: 0.7514 - val_loss: 1.5366 - val_accuracy: 0.6125\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6452 - accuracy: 0.7771 - val_loss: 1.3711 - val_accuracy: 0.6057\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6090 - accuracy: 0.7946 - val_loss: 1.3390 - val_accuracy: 0.6192\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5521 - accuracy: 0.8147 - val_loss: 1.4880 - val_accuracy: 0.6301\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5493 - accuracy: 0.8127 - val_loss: 1.4645 - val_accuracy: 0.6220\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5560 - accuracy: 0.8235 - val_loss: 1.5293 - val_accuracy: 0.6341\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.5237 - accuracy: 0.8224 - val_loss: 1.5318 - val_accuracy: 0.5949\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5086 - accuracy: 0.8317 - val_loss: 1.5216 - val_accuracy: 0.6070\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4559 - accuracy: 0.8399 - val_loss: 1.7004 - val_accuracy: 0.6125\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.4482 - accuracy: 0.8487 - val_loss: 1.6107 - val_accuracy: 0.6030\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.4378 - accuracy: 0.8461 - val_loss: 1.7839 - val_accuracy: 0.6111\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.4090 - accuracy: 0.8652 - val_loss: 1.7854 - val_accuracy: 0.6220\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.4098 - accuracy: 0.8564 - val_loss: 1.8068 - val_accuracy: 0.6030\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.3912 - accuracy: 0.8677 - val_loss: 1.8475 - val_accuracy: 0.6247\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.3727 - accuracy: 0.8785 - val_loss: 1.8950 - val_accuracy: 0.6165\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3619 - accuracy: 0.8791 - val_loss: 1.9048 - val_accuracy: 0.6003\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3587 - accuracy: 0.8791 - val_loss: 1.9362 - val_accuracy: 0.6247\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.3590 - accuracy: 0.8796 - val_loss: 1.9364 - val_accuracy: 0.6314\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.3417 - accuracy: 0.8945 - val_loss: 1.9256 - val_accuracy: 0.6287\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.3425 - accuracy: 0.8857 - val_loss: 1.9847 - val_accuracy: 0.6328\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3413 - accuracy: 0.8868 - val_loss: 1.9701 - val_accuracy: 0.6314\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.3371 - accuracy: 0.8847 - val_loss: 1.9733 - val_accuracy: 0.6314\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.3309 - accuracy: 0.8878 - val_loss: 1.9835 - val_accuracy: 0.6355\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.3320 - accuracy: 0.8899 - val_loss: 1.9731 - val_accuracy: 0.6274\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.3256 - accuracy: 0.8893 - val_loss: 1.9943 - val_accuracy: 0.6341\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3113 - accuracy: 0.8945 - val_loss: 2.0051 - val_accuracy: 0.6314\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3221 - accuracy: 0.8868 - val_loss: 2.0086 - val_accuracy: 0.6369\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3127 - accuracy: 0.9017 - val_loss: 2.0158 - val_accuracy: 0.6369\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3200 - accuracy: 0.9002 - val_loss: 1.9967 - val_accuracy: 0.6314\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.3120 - accuracy: 0.9017 - val_loss: 2.0322 - val_accuracy: 0.6436\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.3212 - accuracy: 0.8955 - val_loss: 2.0001 - val_accuracy: 0.6328\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3082 - accuracy: 0.9002 - val_loss: 2.0110 - val_accuracy: 0.6369\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3113 - accuracy: 0.9012 - val_loss: 2.0661 - val_accuracy: 0.6436\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.3129 - accuracy: 0.8888 - val_loss: 2.0793 - val_accuracy: 0.6423\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.3005 - accuracy: 0.9048 - val_loss: 2.0900 - val_accuracy: 0.6382\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.2877 - accuracy: 0.9094 - val_loss: 2.0892 - val_accuracy: 0.6423\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.2941 - accuracy: 0.9027 - val_loss: 2.0831 - val_accuracy: 0.6382\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2939 - accuracy: 0.9022 - val_loss: 2.1007 - val_accuracy: 0.6369\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.2970 - accuracy: 0.9022 - val_loss: 2.0967 - val_accuracy: 0.6355\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.2965 - accuracy: 0.9063 - val_loss: 2.1050 - val_accuracy: 0.6436\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.2864 - accuracy: 0.9089 - val_loss: 2.1046 - val_accuracy: 0.6409\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.2959 - accuracy: 0.9032 - val_loss: 2.1206 - val_accuracy: 0.6423\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2957 - accuracy: 0.8971 - val_loss: 2.1261 - val_accuracy: 0.6369\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2955 - accuracy: 0.9027 - val_loss: 2.1360 - val_accuracy: 0.6382\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.2930 - accuracy: 0.9110 - val_loss: 2.1246 - val_accuracy: 0.6355\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.2875 - accuracy: 0.9079 - val_loss: 2.1155 - val_accuracy: 0.6369\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.2896 - accuracy: 0.9043 - val_loss: 2.1089 - val_accuracy: 0.6382\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.2928 - accuracy: 0.9074 - val_loss: 2.1149 - val_accuracy: 0.6369\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.2826 - accuracy: 0.9058 - val_loss: 2.1292 - val_accuracy: 0.6396\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.2932 - accuracy: 0.9094 - val_loss: 2.1191 - val_accuracy: 0.6409\n",
      "\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 2.0322 - accuracy: 0.6436\n",
      "Training of model  1\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 2s 79ms/step - loss: 2.4473 - accuracy: 0.3001 - val_loss: 2.1836 - val_accuracy: 0.3532\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 2.1052 - accuracy: 0.3392 - val_loss: 1.9160 - val_accuracy: 0.3743\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.9923 - accuracy: 0.3634 - val_loss: 1.8516 - val_accuracy: 0.3968\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.9269 - accuracy: 0.3829 - val_loss: 1.8096 - val_accuracy: 0.4074\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.8451 - accuracy: 0.3958 - val_loss: 1.7220 - val_accuracy: 0.4153\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.8050 - accuracy: 0.4189 - val_loss: 1.7301 - val_accuracy: 0.4180\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.7572 - accuracy: 0.4225 - val_loss: 1.6019 - val_accuracy: 0.4749\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.6860 - accuracy: 0.4601 - val_loss: 1.5852 - val_accuracy: 0.4762\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.6380 - accuracy: 0.4699 - val_loss: 1.6588 - val_accuracy: 0.4524\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.5844 - accuracy: 0.4920 - val_loss: 1.4967 - val_accuracy: 0.4974\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.5063 - accuracy: 0.4946 - val_loss: 1.9716 - val_accuracy: 0.3889\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.6014 - accuracy: 0.4689 - val_loss: 1.4877 - val_accuracy: 0.5079\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.4435 - accuracy: 0.5306 - val_loss: 1.5196 - val_accuracy: 0.4907\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3908 - accuracy: 0.5311 - val_loss: 1.3323 - val_accuracy: 0.5807\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.3532 - accuracy: 0.5682 - val_loss: 1.3492 - val_accuracy: 0.5661\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.3098 - accuracy: 0.5553 - val_loss: 1.3002 - val_accuracy: 0.5648\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.2099 - accuracy: 0.5893 - val_loss: 1.2849 - val_accuracy: 0.6124\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.1322 - accuracy: 0.6217 - val_loss: 1.2359 - val_accuracy: 0.6362\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.1060 - accuracy: 0.6469 - val_loss: 2.6284 - val_accuracy: 0.5675\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.2411 - accuracy: 0.6001 - val_loss: 1.3647 - val_accuracy: 0.5688\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.1012 - accuracy: 0.6346 - val_loss: 1.2378 - val_accuracy: 0.5952\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.1084 - accuracy: 0.6248 - val_loss: 1.3475 - val_accuracy: 0.5714\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 1.0910 - accuracy: 0.6387 - val_loss: 1.3947 - val_accuracy: 0.5899\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.0005 - accuracy: 0.6593 - val_loss: 1.2678 - val_accuracy: 0.6310\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.8947 - accuracy: 0.6927 - val_loss: 1.2990 - val_accuracy: 0.6310\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8710 - accuracy: 0.7102 - val_loss: 1.2839 - val_accuracy: 0.6429\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.8325 - accuracy: 0.7138 - val_loss: 1.3055 - val_accuracy: 0.6323\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8302 - accuracy: 0.7210 - val_loss: 1.3250 - val_accuracy: 0.6376\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.8372 - accuracy: 0.7118 - val_loss: 1.3315 - val_accuracy: 0.6190\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.8111 - accuracy: 0.7324 - val_loss: 1.3313 - val_accuracy: 0.6442\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.7551 - accuracy: 0.7365 - val_loss: 1.5657 - val_accuracy: 0.6283\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.7495 - accuracy: 0.7463 - val_loss: 1.4155 - val_accuracy: 0.6098\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7168 - accuracy: 0.7643 - val_loss: 1.4869 - val_accuracy: 0.6058\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.7167 - accuracy: 0.7478 - val_loss: 1.3994 - val_accuracy: 0.6270\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6940 - accuracy: 0.7674 - val_loss: 1.4296 - val_accuracy: 0.6243\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.6269 - accuracy: 0.7905 - val_loss: 1.5685 - val_accuracy: 0.6548\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.6032 - accuracy: 0.7946 - val_loss: 1.4934 - val_accuracy: 0.6587\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5834 - accuracy: 0.7967 - val_loss: 1.5550 - val_accuracy: 0.6680\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5629 - accuracy: 0.7993 - val_loss: 1.6618 - val_accuracy: 0.6508\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5776 - accuracy: 0.7931 - val_loss: 1.6769 - val_accuracy: 0.6296\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.5378 - accuracy: 0.8116 - val_loss: 1.6682 - val_accuracy: 0.6376\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5237 - accuracy: 0.8188 - val_loss: 1.6314 - val_accuracy: 0.6481\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4956 - accuracy: 0.8266 - val_loss: 1.6973 - val_accuracy: 0.6270\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4786 - accuracy: 0.8338 - val_loss: 1.7316 - val_accuracy: 0.6614\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4704 - accuracy: 0.8286 - val_loss: 1.7886 - val_accuracy: 0.6746\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4464 - accuracy: 0.8441 - val_loss: 1.7854 - val_accuracy: 0.6786\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4440 - accuracy: 0.8528 - val_loss: 1.7808 - val_accuracy: 0.6415\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4415 - accuracy: 0.8492 - val_loss: 1.8280 - val_accuracy: 0.6534\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4393 - accuracy: 0.8435 - val_loss: 1.8902 - val_accuracy: 0.6852\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.4366 - accuracy: 0.8513 - val_loss: 1.8606 - val_accuracy: 0.6429\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4126 - accuracy: 0.8580 - val_loss: 1.9778 - val_accuracy: 0.6574\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.4224 - accuracy: 0.8569 - val_loss: 1.8925 - val_accuracy: 0.6786\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4014 - accuracy: 0.8590 - val_loss: 2.0497 - val_accuracy: 0.6534\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.3932 - accuracy: 0.8595 - val_loss: 2.1070 - val_accuracy: 0.6680\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3900 - accuracy: 0.8708 - val_loss: 2.0682 - val_accuracy: 0.6627\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3705 - accuracy: 0.8729 - val_loss: 2.0222 - val_accuracy: 0.6561\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3654 - accuracy: 0.8734 - val_loss: 2.0427 - val_accuracy: 0.6614\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3521 - accuracy: 0.8739 - val_loss: 2.1005 - val_accuracy: 0.6653\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3604 - accuracy: 0.8791 - val_loss: 2.1141 - val_accuracy: 0.6614\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3404 - accuracy: 0.8806 - val_loss: 2.1334 - val_accuracy: 0.6574\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3449 - accuracy: 0.8780 - val_loss: 2.1308 - val_accuracy: 0.6534\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3282 - accuracy: 0.8821 - val_loss: 2.1322 - val_accuracy: 0.6627\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.3373 - accuracy: 0.8796 - val_loss: 2.1488 - val_accuracy: 0.6627\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3243 - accuracy: 0.8868 - val_loss: 2.1722 - val_accuracy: 0.6627\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3324 - accuracy: 0.8857 - val_loss: 2.1765 - val_accuracy: 0.6706\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3279 - accuracy: 0.8868 - val_loss: 2.1684 - val_accuracy: 0.6574\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3131 - accuracy: 0.8924 - val_loss: 2.1749 - val_accuracy: 0.6720\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3143 - accuracy: 0.8899 - val_loss: 2.1801 - val_accuracy: 0.6706\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3137 - accuracy: 0.8904 - val_loss: 2.1766 - val_accuracy: 0.6561\n",
      "\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.8902 - accuracy: 0.6852\n",
      "Training of model  2\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 2s 79ms/step - loss: 2.4679 - accuracy: 0.2697 - val_loss: 2.3458 - val_accuracy: 0.3120\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 2.1935 - accuracy: 0.3134 - val_loss: 2.0895 - val_accuracy: 0.3231\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 2.0050 - accuracy: 0.3500 - val_loss: 2.0723 - val_accuracy: 0.3175\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.9714 - accuracy: 0.3587 - val_loss: 1.9696 - val_accuracy: 0.3621\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.9243 - accuracy: 0.3809 - val_loss: 1.9231 - val_accuracy: 0.3663\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 1.8602 - accuracy: 0.4056 - val_loss: 1.8685 - val_accuracy: 0.4011\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.8036 - accuracy: 0.4138 - val_loss: 2.0565 - val_accuracy: 0.3078\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.7508 - accuracy: 0.4081 - val_loss: 1.9690 - val_accuracy: 0.3886\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.6941 - accuracy: 0.4220 - val_loss: 1.9490 - val_accuracy: 0.3579\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 1.6879 - accuracy: 0.4159 - val_loss: 1.7387 - val_accuracy: 0.3983\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.6797 - accuracy: 0.4375 - val_loss: 2.4003 - val_accuracy: 0.4053\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5776 - accuracy: 0.4416 - val_loss: 1.6635 - val_accuracy: 0.4150\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5302 - accuracy: 0.4524 - val_loss: 1.6542 - val_accuracy: 0.4373\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.5016 - accuracy: 0.4601 - val_loss: 1.7458 - val_accuracy: 0.4164\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4388 - accuracy: 0.4951 - val_loss: 1.8580 - val_accuracy: 0.4429\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4598 - accuracy: 0.4812 - val_loss: 1.8575 - val_accuracy: 0.4081\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.4002 - accuracy: 0.4982 - val_loss: 1.5377 - val_accuracy: 0.5153\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3960 - accuracy: 0.4961 - val_loss: 1.4741 - val_accuracy: 0.4763\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.2714 - accuracy: 0.5404 - val_loss: 1.5310 - val_accuracy: 0.5432\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.2611 - accuracy: 0.5445 - val_loss: 1.7324 - val_accuracy: 0.5265\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.1700 - accuracy: 0.5888 - val_loss: 1.4950 - val_accuracy: 0.5265\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1153 - accuracy: 0.6140 - val_loss: 1.3751 - val_accuracy: 0.5334\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1429 - accuracy: 0.6176 - val_loss: 1.3927 - val_accuracy: 0.5627\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.1498 - accuracy: 0.6191 - val_loss: 1.5238 - val_accuracy: 0.5613\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1624 - accuracy: 0.6264 - val_loss: 1.3641 - val_accuracy: 0.5794\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0405 - accuracy: 0.6598 - val_loss: 1.7557 - val_accuracy: 0.5766\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.9572 - accuracy: 0.6783 - val_loss: 1.3330 - val_accuracy: 0.6072\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.9100 - accuracy: 0.6922 - val_loss: 1.4121 - val_accuracy: 0.6198\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.8441 - accuracy: 0.7133 - val_loss: 1.5313 - val_accuracy: 0.6114\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8861 - accuracy: 0.7144 - val_loss: 1.2404 - val_accuracy: 0.6212\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.8660 - accuracy: 0.7210 - val_loss: 1.7512 - val_accuracy: 0.5529\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.9974 - accuracy: 0.6758 - val_loss: 1.3370 - val_accuracy: 0.6212\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.8600 - accuracy: 0.7236 - val_loss: 1.5438 - val_accuracy: 0.6267\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8081 - accuracy: 0.7344 - val_loss: 1.2738 - val_accuracy: 0.6226\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7678 - accuracy: 0.7488 - val_loss: 1.3959 - val_accuracy: 0.5975\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.7290 - accuracy: 0.7535 - val_loss: 1.3046 - val_accuracy: 0.6351\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.7841 - accuracy: 0.7514 - val_loss: 1.5064 - val_accuracy: 0.5752\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8019 - accuracy: 0.7308 - val_loss: 1.3595 - val_accuracy: 0.6072\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.7272 - accuracy: 0.7524 - val_loss: 1.7238 - val_accuracy: 0.6435\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6307 - accuracy: 0.7895 - val_loss: 1.5035 - val_accuracy: 0.6337\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6079 - accuracy: 0.7859 - val_loss: 1.5292 - val_accuracy: 0.6337\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6817 - accuracy: 0.7756 - val_loss: 1.3831 - val_accuracy: 0.6281\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.6504 - accuracy: 0.7869 - val_loss: 1.4691 - val_accuracy: 0.6128\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6038 - accuracy: 0.7967 - val_loss: 1.5924 - val_accuracy: 0.6351\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5301 - accuracy: 0.8302 - val_loss: 1.9268 - val_accuracy: 0.6337\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4996 - accuracy: 0.8312 - val_loss: 1.5948 - val_accuracy: 0.6476\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4648 - accuracy: 0.8435 - val_loss: 2.0928 - val_accuracy: 0.6448\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4566 - accuracy: 0.8451 - val_loss: 2.1026 - val_accuracy: 0.6518\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4123 - accuracy: 0.8605 - val_loss: 1.9949 - val_accuracy: 0.6323\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4067 - accuracy: 0.8626 - val_loss: 2.1613 - val_accuracy: 0.6448\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5837 - accuracy: 0.8518 - val_loss: 3.1004 - val_accuracy: 0.6114\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6828 - accuracy: 0.7988 - val_loss: 2.0708 - val_accuracy: 0.6170\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5691 - accuracy: 0.8369 - val_loss: 2.2967 - val_accuracy: 0.6309\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4526 - accuracy: 0.8497 - val_loss: 1.8353 - val_accuracy: 0.6309\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3979 - accuracy: 0.8641 - val_loss: 1.8932 - val_accuracy: 0.6407\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3610 - accuracy: 0.8785 - val_loss: 2.0077 - val_accuracy: 0.6435\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.3520 - accuracy: 0.8842 - val_loss: 2.1887 - val_accuracy: 0.6560\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3185 - accuracy: 0.8966 - val_loss: 2.2560 - val_accuracy: 0.6504\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.2986 - accuracy: 0.8981 - val_loss: 2.3515 - val_accuracy: 0.6532\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3171 - accuracy: 0.8935 - val_loss: 2.3827 - val_accuracy: 0.6560\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2886 - accuracy: 0.8955 - val_loss: 2.6532 - val_accuracy: 0.6546\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2949 - accuracy: 0.9007 - val_loss: 2.5488 - val_accuracy: 0.6560\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.2790 - accuracy: 0.9027 - val_loss: 2.3970 - val_accuracy: 0.6518\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.2672 - accuracy: 0.9120 - val_loss: 2.4652 - val_accuracy: 0.6546\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.2558 - accuracy: 0.9171 - val_loss: 2.5016 - val_accuracy: 0.6546\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.2381 - accuracy: 0.9187 - val_loss: 2.6101 - val_accuracy: 0.6504\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.2570 - accuracy: 0.9125 - val_loss: 2.5959 - val_accuracy: 0.6671\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2500 - accuracy: 0.9130 - val_loss: 2.6109 - val_accuracy: 0.6574\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2452 - accuracy: 0.9115 - val_loss: 2.6640 - val_accuracy: 0.6532\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.2252 - accuracy: 0.9228 - val_loss: 2.8125 - val_accuracy: 0.6588\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2228 - accuracy: 0.9192 - val_loss: 2.9442 - val_accuracy: 0.6616\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2271 - accuracy: 0.9228 - val_loss: 2.8848 - val_accuracy: 0.6588\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.2091 - accuracy: 0.9243 - val_loss: 2.9574 - val_accuracy: 0.6602\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.2116 - accuracy: 0.9259 - val_loss: 3.0394 - val_accuracy: 0.6560\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2142 - accuracy: 0.9285 - val_loss: 3.0807 - val_accuracy: 0.6560\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1927 - accuracy: 0.9336 - val_loss: 3.1316 - val_accuracy: 0.6643\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.2025 - accuracy: 0.9326 - val_loss: 3.1151 - val_accuracy: 0.6616\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2111 - accuracy: 0.9249 - val_loss: 3.0778 - val_accuracy: 0.6630\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1934 - accuracy: 0.9341 - val_loss: 3.0928 - val_accuracy: 0.6630\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1991 - accuracy: 0.9326 - val_loss: 3.0790 - val_accuracy: 0.6643\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1940 - accuracy: 0.9367 - val_loss: 3.1208 - val_accuracy: 0.6685\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1908 - accuracy: 0.9352 - val_loss: 3.1950 - val_accuracy: 0.6630\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1847 - accuracy: 0.9346 - val_loss: 3.2020 - val_accuracy: 0.6643\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1875 - accuracy: 0.9310 - val_loss: 3.1936 - val_accuracy: 0.6657\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1818 - accuracy: 0.9362 - val_loss: 3.2359 - val_accuracy: 0.6643\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1923 - accuracy: 0.9285 - val_loss: 3.3009 - val_accuracy: 0.6699\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1801 - accuracy: 0.9393 - val_loss: 3.2444 - val_accuracy: 0.6643\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1866 - accuracy: 0.9372 - val_loss: 3.2558 - val_accuracy: 0.6671\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.1819 - accuracy: 0.9382 - val_loss: 3.3195 - val_accuracy: 0.6671\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.1816 - accuracy: 0.9372 - val_loss: 3.3215 - val_accuracy: 0.6657\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1759 - accuracy: 0.9357 - val_loss: 3.2332 - val_accuracy: 0.6657\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.1753 - accuracy: 0.9429 - val_loss: 3.2794 - val_accuracy: 0.6616\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.1681 - accuracy: 0.9377 - val_loss: 3.2517 - val_accuracy: 0.6671\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1756 - accuracy: 0.9352 - val_loss: 3.2989 - val_accuracy: 0.6657\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.1784 - accuracy: 0.9403 - val_loss: 3.3351 - val_accuracy: 0.6671\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1703 - accuracy: 0.9403 - val_loss: 3.3057 - val_accuracy: 0.6616\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.1690 - accuracy: 0.9377 - val_loss: 3.3043 - val_accuracy: 0.6643\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1683 - accuracy: 0.9398 - val_loss: 3.3056 - val_accuracy: 0.6643\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1744 - accuracy: 0.9413 - val_loss: 3.3210 - val_accuracy: 0.6630\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.1742 - accuracy: 0.9352 - val_loss: 3.3366 - val_accuracy: 0.6657\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.1701 - accuracy: 0.9444 - val_loss: 3.3811 - val_accuracy: 0.6630\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.1706 - accuracy: 0.9418 - val_loss: 3.3807 - val_accuracy: 0.6630\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.1630 - accuracy: 0.9480 - val_loss: 3.3660 - val_accuracy: 0.6616\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1735 - accuracy: 0.9398 - val_loss: 3.4119 - val_accuracy: 0.6616\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1600 - accuracy: 0.9490 - val_loss: 3.4038 - val_accuracy: 0.6630\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.1728 - accuracy: 0.9408 - val_loss: 3.4074 - val_accuracy: 0.6643\n",
      "\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 3.3009 - accuracy: 0.6699\n",
      "Training of model  3\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 2s 81ms/step - loss: 2.4638 - accuracy: 0.2913 - val_loss: 2.4003 - val_accuracy: 0.2974\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 2.1695 - accuracy: 0.3299 - val_loss: 2.1921 - val_accuracy: 0.3154\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.9603 - accuracy: 0.3767 - val_loss: 2.0259 - val_accuracy: 0.3306\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.8946 - accuracy: 0.3860 - val_loss: 2.0158 - val_accuracy: 0.3375\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.8566 - accuracy: 0.4107 - val_loss: 1.9235 - val_accuracy: 0.3748\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.7958 - accuracy: 0.4272 - val_loss: 1.9042 - val_accuracy: 0.3679\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.7033 - accuracy: 0.4272 - val_loss: 1.8314 - val_accuracy: 0.3845\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.7205 - accuracy: 0.4354 - val_loss: 1.9026 - val_accuracy: 0.3831\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.7155 - accuracy: 0.4375 - val_loss: 1.8153 - val_accuracy: 0.3900\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.6117 - accuracy: 0.4575 - val_loss: 1.7111 - val_accuracy: 0.4136\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.5501 - accuracy: 0.4807 - val_loss: 1.7650 - val_accuracy: 0.4371\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5438 - accuracy: 0.5049 - val_loss: 1.6311 - val_accuracy: 0.4661\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4575 - accuracy: 0.5188 - val_loss: 1.8381 - val_accuracy: 0.4481\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.6639 - accuracy: 0.4812 - val_loss: 1.7057 - val_accuracy: 0.4398\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.5046 - accuracy: 0.5100 - val_loss: 1.6976 - val_accuracy: 0.4467\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 1.4178 - accuracy: 0.5332 - val_loss: 1.6626 - val_accuracy: 0.4661\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.3339 - accuracy: 0.5641 - val_loss: 1.5523 - val_accuracy: 0.4703\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.3559 - accuracy: 0.5600 - val_loss: 1.5375 - val_accuracy: 0.4550\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3680 - accuracy: 0.5435 - val_loss: 1.5985 - val_accuracy: 0.4398\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3114 - accuracy: 0.5528 - val_loss: 1.4549 - val_accuracy: 0.4979\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.2885 - accuracy: 0.5744 - val_loss: 1.6267 - val_accuracy: 0.4716\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.2686 - accuracy: 0.5744 - val_loss: 1.5992 - val_accuracy: 0.4993\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.2043 - accuracy: 0.5893 - val_loss: 1.5212 - val_accuracy: 0.5201\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1408 - accuracy: 0.6248 - val_loss: 1.4472 - val_accuracy: 0.5491\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.0404 - accuracy: 0.6783 - val_loss: 1.5792 - val_accuracy: 0.5519\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 1.0155 - accuracy: 0.6835 - val_loss: 1.5352 - val_accuracy: 0.5533\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.9662 - accuracy: 0.7020 - val_loss: 1.3955 - val_accuracy: 0.5380\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.9715 - accuracy: 0.6824 - val_loss: 1.3618 - val_accuracy: 0.5768\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.8653 - accuracy: 0.7226 - val_loss: 1.5186 - val_accuracy: 0.5823\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.8629 - accuracy: 0.7210 - val_loss: 1.3645 - val_accuracy: 0.6003\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8702 - accuracy: 0.7355 - val_loss: 1.3861 - val_accuracy: 0.5726\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.8139 - accuracy: 0.7437 - val_loss: 1.4950 - val_accuracy: 0.5795\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.8608 - accuracy: 0.7385 - val_loss: 1.3515 - val_accuracy: 0.5726\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8510 - accuracy: 0.7396 - val_loss: 1.3545 - val_accuracy: 0.5823\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.7797 - accuracy: 0.7535 - val_loss: 1.4156 - val_accuracy: 0.5947\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.7192 - accuracy: 0.7669 - val_loss: 1.4211 - val_accuracy: 0.5934\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6488 - accuracy: 0.7952 - val_loss: 1.5885 - val_accuracy: 0.6072\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6052 - accuracy: 0.7957 - val_loss: 1.4822 - val_accuracy: 0.6003\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5933 - accuracy: 0.8070 - val_loss: 1.4940 - val_accuracy: 0.5947\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.6092 - accuracy: 0.8029 - val_loss: 1.5761 - val_accuracy: 0.6030\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6199 - accuracy: 0.7998 - val_loss: 1.5230 - val_accuracy: 0.6030\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5667 - accuracy: 0.8116 - val_loss: 1.4919 - val_accuracy: 0.6266\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5260 - accuracy: 0.8250 - val_loss: 1.6664 - val_accuracy: 0.5975\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5431 - accuracy: 0.8116 - val_loss: 1.5392 - val_accuracy: 0.6169\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.6440 - accuracy: 0.8183 - val_loss: 1.5914 - val_accuracy: 0.5961\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6346 - accuracy: 0.8029 - val_loss: 1.8149 - val_accuracy: 0.5837\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.5394 - accuracy: 0.8209 - val_loss: 1.7894 - val_accuracy: 0.6030\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4881 - accuracy: 0.8379 - val_loss: 1.8607 - val_accuracy: 0.6155\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4530 - accuracy: 0.8446 - val_loss: 1.9832 - val_accuracy: 0.6072\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4212 - accuracy: 0.8559 - val_loss: 1.9989 - val_accuracy: 0.6003\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4128 - accuracy: 0.8554 - val_loss: 2.1067 - val_accuracy: 0.6100\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4106 - accuracy: 0.8580 - val_loss: 2.1276 - val_accuracy: 0.6086\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3788 - accuracy: 0.8708 - val_loss: 2.2630 - val_accuracy: 0.6155\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3644 - accuracy: 0.8775 - val_loss: 2.3238 - val_accuracy: 0.6169\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3702 - accuracy: 0.8806 - val_loss: 2.2876 - val_accuracy: 0.6141\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.3612 - accuracy: 0.8734 - val_loss: 2.3067 - val_accuracy: 0.6030\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3628 - accuracy: 0.8718 - val_loss: 2.3382 - val_accuracy: 0.6072\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3466 - accuracy: 0.8775 - val_loss: 2.3119 - val_accuracy: 0.6072\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3499 - accuracy: 0.8796 - val_loss: 2.3152 - val_accuracy: 0.6113\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3403 - accuracy: 0.8821 - val_loss: 2.3115 - val_accuracy: 0.6072\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3420 - accuracy: 0.8847 - val_loss: 2.3004 - val_accuracy: 0.6100\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3313 - accuracy: 0.8821 - val_loss: 2.3401 - val_accuracy: 0.6072\n",
      "\n",
      "23/23 [==============================] - 0s 15ms/step - loss: 1.4919 - accuracy: 0.6266\n",
      "Training of model  4\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 3s 80ms/step - loss: 2.4224 - accuracy: 0.2815 - val_loss: 2.2589 - val_accuracy: 0.3251\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 2.0951 - accuracy: 0.3587 - val_loss: 2.0488 - val_accuracy: 0.3238\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.9508 - accuracy: 0.3675 - val_loss: 1.9899 - val_accuracy: 0.3443\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.9009 - accuracy: 0.3742 - val_loss: 1.9544 - val_accuracy: 0.3566\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.8599 - accuracy: 0.3978 - val_loss: 1.8826 - val_accuracy: 0.3893\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.7835 - accuracy: 0.4220 - val_loss: 1.8463 - val_accuracy: 0.3989\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.7231 - accuracy: 0.4308 - val_loss: 1.8813 - val_accuracy: 0.3374\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.7649 - accuracy: 0.4277 - val_loss: 1.7039 - val_accuracy: 0.4057\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.8466 - accuracy: 0.4020 - val_loss: 1.8165 - val_accuracy: 0.3866\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.7204 - accuracy: 0.4364 - val_loss: 1.7525 - val_accuracy: 0.3975\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.6536 - accuracy: 0.4457 - val_loss: 1.6882 - val_accuracy: 0.4071\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.6276 - accuracy: 0.4503 - val_loss: 1.8137 - val_accuracy: 0.4057\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.6982 - accuracy: 0.4411 - val_loss: 1.7463 - val_accuracy: 0.4208\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5680 - accuracy: 0.4735 - val_loss: 1.5972 - val_accuracy: 0.4385\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.4582 - accuracy: 0.5136 - val_loss: 1.6062 - val_accuracy: 0.4331\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.3659 - accuracy: 0.5383 - val_loss: 1.4679 - val_accuracy: 0.4973\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3735 - accuracy: 0.5579 - val_loss: 1.5443 - val_accuracy: 0.4658\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.3468 - accuracy: 0.5492 - val_loss: 1.6116 - val_accuracy: 0.4440\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3904 - accuracy: 0.5440 - val_loss: 1.4557 - val_accuracy: 0.5041\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.2646 - accuracy: 0.5867 - val_loss: 1.3881 - val_accuracy: 0.5464\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.1049 - accuracy: 0.6433 - val_loss: 1.9114 - val_accuracy: 0.4672\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3457 - accuracy: 0.5564 - val_loss: 1.4203 - val_accuracy: 0.4727\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1158 - accuracy: 0.6207 - val_loss: 1.3483 - val_accuracy: 0.5560\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.9873 - accuracy: 0.6716 - val_loss: 1.4448 - val_accuracy: 0.5383\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.9318 - accuracy: 0.6953 - val_loss: 1.5003 - val_accuracy: 0.5478\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.8847 - accuracy: 0.7051 - val_loss: 1.5873 - val_accuracy: 0.5738\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.9233 - accuracy: 0.6958 - val_loss: 1.6184 - val_accuracy: 0.5437\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 32ms/step - loss: 0.8527 - accuracy: 0.7149 - val_loss: 1.5802 - val_accuracy: 0.5642\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.9021 - accuracy: 0.7154 - val_loss: 1.4822 - val_accuracy: 0.5820\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.9670 - accuracy: 0.7123 - val_loss: 1.4846 - val_accuracy: 0.5273\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8882 - accuracy: 0.7133 - val_loss: 1.5708 - val_accuracy: 0.5546\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8027 - accuracy: 0.7437 - val_loss: 1.4280 - val_accuracy: 0.5697\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.7803 - accuracy: 0.7463 - val_loss: 1.5352 - val_accuracy: 0.5260\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0107 - accuracy: 0.6680 - val_loss: 1.3509 - val_accuracy: 0.5751\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.7718 - accuracy: 0.7411 - val_loss: 1.7952 - val_accuracy: 0.5861\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6727 - accuracy: 0.7777 - val_loss: 1.6443 - val_accuracy: 0.5902\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.6489 - accuracy: 0.7869 - val_loss: 1.6308 - val_accuracy: 0.5943\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6066 - accuracy: 0.8003 - val_loss: 1.6630 - val_accuracy: 0.5984\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5867 - accuracy: 0.7998 - val_loss: 1.7955 - val_accuracy: 0.5984\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.5874 - accuracy: 0.8044 - val_loss: 1.8116 - val_accuracy: 0.5956\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5733 - accuracy: 0.8147 - val_loss: 1.5916 - val_accuracy: 0.5861\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5737 - accuracy: 0.8008 - val_loss: 1.7838 - val_accuracy: 0.6052\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.5330 - accuracy: 0.8214 - val_loss: 1.7628 - val_accuracy: 0.6011\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5290 - accuracy: 0.8219 - val_loss: 1.8419 - val_accuracy: 0.6052\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5092 - accuracy: 0.8214 - val_loss: 1.8226 - val_accuracy: 0.6038\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5018 - accuracy: 0.8286 - val_loss: 2.2495 - val_accuracy: 0.5902\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4800 - accuracy: 0.8332 - val_loss: 2.2563 - val_accuracy: 0.5929\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4405 - accuracy: 0.8507 - val_loss: 2.1044 - val_accuracy: 0.6148\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4139 - accuracy: 0.8559 - val_loss: 2.3623 - val_accuracy: 0.6270\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.3954 - accuracy: 0.8621 - val_loss: 2.3089 - val_accuracy: 0.6107\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3969 - accuracy: 0.8626 - val_loss: 2.4342 - val_accuracy: 0.6052\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3863 - accuracy: 0.8677 - val_loss: 2.8226 - val_accuracy: 0.6107\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4508 - accuracy: 0.8590 - val_loss: 2.4470 - val_accuracy: 0.6079\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3721 - accuracy: 0.8760 - val_loss: 2.6351 - val_accuracy: 0.6189\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3433 - accuracy: 0.8811 - val_loss: 2.5507 - val_accuracy: 0.6230\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3494 - accuracy: 0.8755 - val_loss: 2.5429 - val_accuracy: 0.6120\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.3278 - accuracy: 0.8888 - val_loss: 2.6035 - val_accuracy: 0.6243\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3033 - accuracy: 0.8960 - val_loss: 2.7099 - val_accuracy: 0.6339\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3007 - accuracy: 0.8986 - val_loss: 2.8788 - val_accuracy: 0.6380\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.2971 - accuracy: 0.8924 - val_loss: 2.7949 - val_accuracy: 0.6175\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.2943 - accuracy: 0.9002 - val_loss: 2.7841 - val_accuracy: 0.6311\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2929 - accuracy: 0.9017 - val_loss: 2.7076 - val_accuracy: 0.6216\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2935 - accuracy: 0.8991 - val_loss: 2.9413 - val_accuracy: 0.6148\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2829 - accuracy: 0.9043 - val_loss: 2.9480 - val_accuracy: 0.6189\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2669 - accuracy: 0.9084 - val_loss: 2.9788 - val_accuracy: 0.6093\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2630 - accuracy: 0.9146 - val_loss: 2.9575 - val_accuracy: 0.6052\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2492 - accuracy: 0.9269 - val_loss: 3.0651 - val_accuracy: 0.6243\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.2342 - accuracy: 0.9254 - val_loss: 3.1783 - val_accuracy: 0.6325\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2535 - accuracy: 0.9171 - val_loss: 3.2262 - val_accuracy: 0.6257\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2386 - accuracy: 0.9202 - val_loss: 3.1413 - val_accuracy: 0.6175\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2284 - accuracy: 0.9285 - val_loss: 3.1902 - val_accuracy: 0.6243\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2335 - accuracy: 0.9243 - val_loss: 3.2220 - val_accuracy: 0.6270\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2269 - accuracy: 0.9274 - val_loss: 3.1725 - val_accuracy: 0.6243\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2390 - accuracy: 0.9202 - val_loss: 3.2331 - val_accuracy: 0.6202\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2178 - accuracy: 0.9285 - val_loss: 3.2618 - val_accuracy: 0.6189\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2210 - accuracy: 0.9264 - val_loss: 3.2581 - val_accuracy: 0.6175\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2202 - accuracy: 0.9326 - val_loss: 3.2837 - val_accuracy: 0.6202\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2204 - accuracy: 0.9290 - val_loss: 3.2950 - val_accuracy: 0.6230\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2209 - accuracy: 0.9331 - val_loss: 3.2744 - val_accuracy: 0.6161\n",
      "\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 2.8788 - accuracy: 0.6380\n",
      "Training of model  5\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 2s 58ms/step - loss: 2.4484 - accuracy: 0.3083 - val_loss: 2.2305 - val_accuracy: 0.3290\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 2.1016 - accuracy: 0.3525 - val_loss: 2.0056 - val_accuracy: 0.3305\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.9960 - accuracy: 0.3556 - val_loss: 1.9754 - val_accuracy: 0.3448\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.9329 - accuracy: 0.3736 - val_loss: 1.9011 - val_accuracy: 0.3705\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 1.8773 - accuracy: 0.4117 - val_loss: 1.8877 - val_accuracy: 0.3748\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.8177 - accuracy: 0.4236 - val_loss: 1.8655 - val_accuracy: 0.3734\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.7671 - accuracy: 0.4215 - val_loss: 1.8268 - val_accuracy: 0.3906\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.7063 - accuracy: 0.4375 - val_loss: 1.7275 - val_accuracy: 0.4049\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.6570 - accuracy: 0.4442 - val_loss: 1.6742 - val_accuracy: 0.4278\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.6423 - accuracy: 0.4483 - val_loss: 1.7451 - val_accuracy: 0.4292\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.5701 - accuracy: 0.4653 - val_loss: 1.7274 - val_accuracy: 0.4392\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4903 - accuracy: 0.4771 - val_loss: 1.5809 - val_accuracy: 0.4506\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.4191 - accuracy: 0.5044 - val_loss: 1.5445 - val_accuracy: 0.4936\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3509 - accuracy: 0.5353 - val_loss: 1.5384 - val_accuracy: 0.5279\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3779 - accuracy: 0.5244 - val_loss: 1.6041 - val_accuracy: 0.4950\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.2873 - accuracy: 0.5435 - val_loss: 1.4791 - val_accuracy: 0.5136\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.1880 - accuracy: 0.5908 - val_loss: 1.4677 - val_accuracy: 0.5107\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.1650 - accuracy: 0.6058 - val_loss: 1.4626 - val_accuracy: 0.5680\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.0885 - accuracy: 0.6377 - val_loss: 1.4221 - val_accuracy: 0.5465\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.0949 - accuracy: 0.6423 - val_loss: 1.4397 - val_accuracy: 0.5694\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1790 - accuracy: 0.6155 - val_loss: 1.4361 - val_accuracy: 0.5436\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0271 - accuracy: 0.6572 - val_loss: 1.4712 - val_accuracy: 0.5894\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.9992 - accuracy: 0.6711 - val_loss: 1.3979 - val_accuracy: 0.6152\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.8906 - accuracy: 0.7200 - val_loss: 1.5072 - val_accuracy: 0.6152\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.8664 - accuracy: 0.7128 - val_loss: 1.7047 - val_accuracy: 0.5007\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.0232 - accuracy: 0.6871 - val_loss: 1.5274 - val_accuracy: 0.5694\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.9416 - accuracy: 0.6963 - val_loss: 1.4249 - val_accuracy: 0.5866\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8143 - accuracy: 0.7416 - val_loss: 1.5663 - val_accuracy: 0.5994\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.7264 - accuracy: 0.7663 - val_loss: 1.6053 - val_accuracy: 0.6009\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.6811 - accuracy: 0.7766 - val_loss: 1.5259 - val_accuracy: 0.6023\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.7164 - accuracy: 0.7684 - val_loss: 1.6538 - val_accuracy: 0.6195\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.6574 - accuracy: 0.7849 - val_loss: 1.7374 - val_accuracy: 0.6323\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6101 - accuracy: 0.7988 - val_loss: 1.7346 - val_accuracy: 0.6237\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.6251 - accuracy: 0.7900 - val_loss: 1.6984 - val_accuracy: 0.6237\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.6076 - accuracy: 0.8034 - val_loss: 1.7174 - val_accuracy: 0.6266\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.5710 - accuracy: 0.8080 - val_loss: 1.7396 - val_accuracy: 0.6180\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.5513 - accuracy: 0.8183 - val_loss: 2.2409 - val_accuracy: 0.6323\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5658 - accuracy: 0.8178 - val_loss: 1.7011 - val_accuracy: 0.5937\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4998 - accuracy: 0.8405 - val_loss: 2.0126 - val_accuracy: 0.6295\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.4812 - accuracy: 0.8430 - val_loss: 1.9874 - val_accuracy: 0.5966\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4773 - accuracy: 0.8507 - val_loss: 1.9792 - val_accuracy: 0.6080\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4582 - accuracy: 0.8523 - val_loss: 2.0877 - val_accuracy: 0.5794\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4332 - accuracy: 0.8523 - val_loss: 2.1517 - val_accuracy: 0.6152\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4285 - accuracy: 0.8538 - val_loss: 2.1875 - val_accuracy: 0.6123\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4036 - accuracy: 0.8698 - val_loss: 2.3189 - val_accuracy: 0.6180\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4045 - accuracy: 0.8646 - val_loss: 2.3975 - val_accuracy: 0.6295\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4092 - accuracy: 0.8677 - val_loss: 2.2450 - val_accuracy: 0.6209\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3817 - accuracy: 0.8729 - val_loss: 2.2945 - val_accuracy: 0.6323\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3728 - accuracy: 0.8729 - val_loss: 2.2802 - val_accuracy: 0.6338\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3767 - accuracy: 0.8734 - val_loss: 2.2898 - val_accuracy: 0.6109\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3641 - accuracy: 0.8811 - val_loss: 2.3528 - val_accuracy: 0.6195\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3575 - accuracy: 0.8847 - val_loss: 2.4949 - val_accuracy: 0.6252\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3513 - accuracy: 0.8857 - val_loss: 2.5613 - val_accuracy: 0.6266\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3391 - accuracy: 0.8863 - val_loss: 2.5468 - val_accuracy: 0.6280\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3418 - accuracy: 0.8868 - val_loss: 2.5957 - val_accuracy: 0.6237\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3450 - accuracy: 0.8857 - val_loss: 2.5941 - val_accuracy: 0.6109\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3355 - accuracy: 0.8888 - val_loss: 2.6204 - val_accuracy: 0.6237\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3407 - accuracy: 0.8863 - val_loss: 2.6289 - val_accuracy: 0.6252\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3234 - accuracy: 0.8893 - val_loss: 2.6258 - val_accuracy: 0.6195\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3297 - accuracy: 0.8888 - val_loss: 2.6440 - val_accuracy: 0.6209\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.3387 - accuracy: 0.8868 - val_loss: 2.6456 - val_accuracy: 0.6195\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3287 - accuracy: 0.8929 - val_loss: 2.6559 - val_accuracy: 0.6252\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3231 - accuracy: 0.8873 - val_loss: 2.6685 - val_accuracy: 0.6209\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.3292 - accuracy: 0.8914 - val_loss: 2.6818 - val_accuracy: 0.6209\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3293 - accuracy: 0.8878 - val_loss: 2.6873 - val_accuracy: 0.6195\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3340 - accuracy: 0.8873 - val_loss: 2.6851 - val_accuracy: 0.6195\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3326 - accuracy: 0.8857 - val_loss: 2.6849 - val_accuracy: 0.6266\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3226 - accuracy: 0.8971 - val_loss: 2.6743 - val_accuracy: 0.6180\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3292 - accuracy: 0.8914 - val_loss: 2.6675 - val_accuracy: 0.6166\n",
      "\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 2.2802 - accuracy: 0.6338\n",
      "Training of model  6\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 3s 80ms/step - loss: 2.4081 - accuracy: 0.2424 - val_loss: 2.2402 - val_accuracy: 0.3352\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 2.1843 - accuracy: 0.3011 - val_loss: 2.0593 - val_accuracy: 0.3535\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 2.0546 - accuracy: 0.3387 - val_loss: 1.9417 - val_accuracy: 0.3732\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 2.0331 - accuracy: 0.3495 - val_loss: 1.8574 - val_accuracy: 0.4014\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.9786 - accuracy: 0.3706 - val_loss: 1.8241 - val_accuracy: 0.3944\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.9109 - accuracy: 0.3860 - val_loss: 1.8114 - val_accuracy: 0.4014\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.8516 - accuracy: 0.3978 - val_loss: 1.7970 - val_accuracy: 0.4127\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.7715 - accuracy: 0.4040 - val_loss: 1.6853 - val_accuracy: 0.4310\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.7080 - accuracy: 0.4195 - val_loss: 1.6339 - val_accuracy: 0.4451\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.6865 - accuracy: 0.4411 - val_loss: 1.6213 - val_accuracy: 0.4465\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.6145 - accuracy: 0.4524 - val_loss: 1.5855 - val_accuracy: 0.4746\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5389 - accuracy: 0.4925 - val_loss: 1.5867 - val_accuracy: 0.4662\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5931 - accuracy: 0.4647 - val_loss: 1.6108 - val_accuracy: 0.4535\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5760 - accuracy: 0.4683 - val_loss: 1.4714 - val_accuracy: 0.5099\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.4269 - accuracy: 0.5147 - val_loss: 1.4098 - val_accuracy: 0.4915\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.4095 - accuracy: 0.5142 - val_loss: 1.5870 - val_accuracy: 0.4662\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.4078 - accuracy: 0.5095 - val_loss: 1.6014 - val_accuracy: 0.5085\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3234 - accuracy: 0.5358 - val_loss: 1.4774 - val_accuracy: 0.5197\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.2678 - accuracy: 0.5507 - val_loss: 1.4767 - val_accuracy: 0.5338\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 1.2154 - accuracy: 0.5754 - val_loss: 1.5226 - val_accuracy: 0.4958\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.2401 - accuracy: 0.5661 - val_loss: 1.4281 - val_accuracy: 0.5338\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 1.1677 - accuracy: 0.5857 - val_loss: 1.3875 - val_accuracy: 0.5268\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.2289 - accuracy: 0.5780 - val_loss: 1.4864 - val_accuracy: 0.5282\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.1664 - accuracy: 0.5769 - val_loss: 1.4189 - val_accuracy: 0.5451\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.1271 - accuracy: 0.5883 - val_loss: 1.6422 - val_accuracy: 0.5493\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.1562 - accuracy: 0.5893 - val_loss: 1.5558 - val_accuracy: 0.5465\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1095 - accuracy: 0.5970 - val_loss: 1.3207 - val_accuracy: 0.5817\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.0034 - accuracy: 0.6557 - val_loss: 1.8293 - val_accuracy: 0.5732\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.0419 - accuracy: 0.6552 - val_loss: 1.7440 - val_accuracy: 0.5296\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 1.0989 - accuracy: 0.6444 - val_loss: 1.4824 - val_accuracy: 0.5014\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.9831 - accuracy: 0.6722 - val_loss: 1.6235 - val_accuracy: 0.5930\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.0058 - accuracy: 0.6665 - val_loss: 2.2169 - val_accuracy: 0.5662\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.1784 - accuracy: 0.6155 - val_loss: 1.4226 - val_accuracy: 0.5930\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.9743 - accuracy: 0.6691 - val_loss: 1.3027 - val_accuracy: 0.5873\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.8732 - accuracy: 0.6984 - val_loss: 1.4090 - val_accuracy: 0.6070\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8250 - accuracy: 0.7061 - val_loss: 2.0269 - val_accuracy: 0.5944\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.8900 - accuracy: 0.7061 - val_loss: 1.3491 - val_accuracy: 0.5986\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8099 - accuracy: 0.7267 - val_loss: 1.5340 - val_accuracy: 0.5845\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8184 - accuracy: 0.7216 - val_loss: 1.3071 - val_accuracy: 0.6239\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.7693 - accuracy: 0.7427 - val_loss: 1.5787 - val_accuracy: 0.6254\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.7101 - accuracy: 0.7622 - val_loss: 1.4686 - val_accuracy: 0.6056\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.7536 - accuracy: 0.7545 - val_loss: 1.4695 - val_accuracy: 0.6070\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.7752 - accuracy: 0.7339 - val_loss: 1.9006 - val_accuracy: 0.5845\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8416 - accuracy: 0.7221 - val_loss: 1.3533 - val_accuracy: 0.6085\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.0364 - accuracy: 0.6938 - val_loss: 1.6883 - val_accuracy: 0.5859\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.7525 - accuracy: 0.7478 - val_loss: 1.6991 - val_accuracy: 0.6141\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6379 - accuracy: 0.7833 - val_loss: 1.4969 - val_accuracy: 0.6324\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5659 - accuracy: 0.8096 - val_loss: 1.6117 - val_accuracy: 0.6169\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5834 - accuracy: 0.8188 - val_loss: 1.8430 - val_accuracy: 0.6113\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5562 - accuracy: 0.8132 - val_loss: 1.7536 - val_accuracy: 0.6268\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 1s 40ms/step - loss: 0.5119 - accuracy: 0.8219 - val_loss: 1.6509 - val_accuracy: 0.6211\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4768 - accuracy: 0.8348 - val_loss: 1.9408 - val_accuracy: 0.6155\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4261 - accuracy: 0.8549 - val_loss: 1.8057 - val_accuracy: 0.6408\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4231 - accuracy: 0.8600 - val_loss: 1.9462 - val_accuracy: 0.6324\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4060 - accuracy: 0.8600 - val_loss: 1.8704 - val_accuracy: 0.6451\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4198 - accuracy: 0.8605 - val_loss: 1.9681 - val_accuracy: 0.6310\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4084 - accuracy: 0.8662 - val_loss: 1.9508 - val_accuracy: 0.6296\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3758 - accuracy: 0.8775 - val_loss: 2.0344 - val_accuracy: 0.6437\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3444 - accuracy: 0.8878 - val_loss: 2.1408 - val_accuracy: 0.6310\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3604 - accuracy: 0.8842 - val_loss: 2.3214 - val_accuracy: 0.6183\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3269 - accuracy: 0.8945 - val_loss: 2.2272 - val_accuracy: 0.6437\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3141 - accuracy: 0.8935 - val_loss: 2.2570 - val_accuracy: 0.6338\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2971 - accuracy: 0.9058 - val_loss: 2.2639 - val_accuracy: 0.6437\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2955 - accuracy: 0.9032 - val_loss: 2.2603 - val_accuracy: 0.6268\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2981 - accuracy: 0.9012 - val_loss: 2.3288 - val_accuracy: 0.6423\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.2784 - accuracy: 0.9099 - val_loss: 2.3535 - val_accuracy: 0.6366\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.2680 - accuracy: 0.9038 - val_loss: 2.3530 - val_accuracy: 0.6352\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2784 - accuracy: 0.9068 - val_loss: 2.3667 - val_accuracy: 0.6423\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2802 - accuracy: 0.9017 - val_loss: 2.3339 - val_accuracy: 0.6380\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.2756 - accuracy: 0.9079 - val_loss: 2.3457 - val_accuracy: 0.6451\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.2610 - accuracy: 0.9130 - val_loss: 2.3464 - val_accuracy: 0.6296\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2525 - accuracy: 0.9171 - val_loss: 2.3977 - val_accuracy: 0.6352\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2608 - accuracy: 0.9156 - val_loss: 2.3958 - val_accuracy: 0.6366\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2614 - accuracy: 0.9171 - val_loss: 2.4102 - val_accuracy: 0.6352\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2456 - accuracy: 0.9228 - val_loss: 2.3992 - val_accuracy: 0.6324\n",
      "\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.8704 - accuracy: 0.6451\n",
      "Training of model  7\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 2s 80ms/step - loss: 2.4605 - accuracy: 0.2748 - val_loss: 2.3128 - val_accuracy: 0.3174\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 2.1377 - accuracy: 0.3453 - val_loss: 2.0252 - val_accuracy: 0.3379\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 1.9601 - accuracy: 0.3623 - val_loss: 1.9675 - val_accuracy: 0.3666\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.8522 - accuracy: 0.3911 - val_loss: 1.8383 - val_accuracy: 0.3871\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.7939 - accuracy: 0.3942 - val_loss: 1.9462 - val_accuracy: 0.3721\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.8342 - accuracy: 0.4014 - val_loss: 1.7725 - val_accuracy: 0.3981\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.7362 - accuracy: 0.4097 - val_loss: 1.7150 - val_accuracy: 0.4131\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.7055 - accuracy: 0.4184 - val_loss: 1.6947 - val_accuracy: 0.4241\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.6059 - accuracy: 0.4539 - val_loss: 1.6721 - val_accuracy: 0.4200\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.6243 - accuracy: 0.4493 - val_loss: 1.7751 - val_accuracy: 0.4200\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.7339 - accuracy: 0.4292 - val_loss: 1.6741 - val_accuracy: 0.4364\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.6125 - accuracy: 0.4488 - val_loss: 1.5753 - val_accuracy: 0.4610\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 1.4856 - accuracy: 0.4792 - val_loss: 1.6208 - val_accuracy: 0.4706\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.4525 - accuracy: 0.5013 - val_loss: 1.4856 - val_accuracy: 0.5103\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4170 - accuracy: 0.4967 - val_loss: 1.5179 - val_accuracy: 0.4829\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3424 - accuracy: 0.5214 - val_loss: 1.4575 - val_accuracy: 0.5089\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3097 - accuracy: 0.5378 - val_loss: 1.3488 - val_accuracy: 0.5349\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.2124 - accuracy: 0.5769 - val_loss: 1.9856 - val_accuracy: 0.4487\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.4372 - accuracy: 0.4936 - val_loss: 1.4652 - val_accuracy: 0.5007\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.2755 - accuracy: 0.5486 - val_loss: 1.4872 - val_accuracy: 0.5376\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1688 - accuracy: 0.5769 - val_loss: 1.3863 - val_accuracy: 0.5321\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.1410 - accuracy: 0.6078 - val_loss: 1.3518 - val_accuracy: 0.5554\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 1.0651 - accuracy: 0.6336 - val_loss: 1.4325 - val_accuracy: 0.5841\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.2153 - accuracy: 0.5970 - val_loss: 1.7022 - val_accuracy: 0.5335\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.7514 - accuracy: 0.4683 - val_loss: 1.5814 - val_accuracy: 0.4815\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.4265 - accuracy: 0.5126 - val_loss: 1.4178 - val_accuracy: 0.5103\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.2483 - accuracy: 0.5780 - val_loss: 1.3175 - val_accuracy: 0.5650\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.1835 - accuracy: 0.6027 - val_loss: 1.3245 - val_accuracy: 0.5814\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.1061 - accuracy: 0.6197 - val_loss: 1.2349 - val_accuracy: 0.5992\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.0471 - accuracy: 0.6382 - val_loss: 1.2231 - val_accuracy: 0.6033\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 1.0019 - accuracy: 0.6459 - val_loss: 1.2338 - val_accuracy: 0.5951\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.9744 - accuracy: 0.6624 - val_loss: 1.2369 - val_accuracy: 0.5882\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.9471 - accuracy: 0.6598 - val_loss: 1.1659 - val_accuracy: 0.6211\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8954 - accuracy: 0.6788 - val_loss: 1.5370 - val_accuracy: 0.5746\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0273 - accuracy: 0.6413 - val_loss: 1.1741 - val_accuracy: 0.6334\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.9116 - accuracy: 0.6897 - val_loss: 1.1615 - val_accuracy: 0.6334\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8482 - accuracy: 0.7092 - val_loss: 1.1875 - val_accuracy: 0.6293\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8246 - accuracy: 0.7159 - val_loss: 1.1531 - val_accuracy: 0.6539\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.7813 - accuracy: 0.7313 - val_loss: 1.2174 - val_accuracy: 0.6594\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.7765 - accuracy: 0.7442 - val_loss: 1.1665 - val_accuracy: 0.6211\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.7918 - accuracy: 0.7406 - val_loss: 1.2278 - val_accuracy: 0.6306\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8195 - accuracy: 0.7200 - val_loss: 1.2810 - val_accuracy: 0.6156\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.7841 - accuracy: 0.7262 - val_loss: 1.1691 - val_accuracy: 0.6566\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.7035 - accuracy: 0.7530 - val_loss: 1.1705 - val_accuracy: 0.6621\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.6628 - accuracy: 0.7669 - val_loss: 1.1527 - val_accuracy: 0.6566\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.6716 - accuracy: 0.7679 - val_loss: 1.2407 - val_accuracy: 0.6553\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6914 - accuracy: 0.7648 - val_loss: 1.4224 - val_accuracy: 0.6183\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.7157 - accuracy: 0.7488 - val_loss: 1.1919 - val_accuracy: 0.6621\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.6236 - accuracy: 0.7900 - val_loss: 1.2465 - val_accuracy: 0.6676\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6050 - accuracy: 0.7910 - val_loss: 1.2524 - val_accuracy: 0.6443\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.6201 - accuracy: 0.7895 - val_loss: 1.2410 - val_accuracy: 0.6512\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5742 - accuracy: 0.8055 - val_loss: 1.3332 - val_accuracy: 0.6252\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.5776 - accuracy: 0.8008 - val_loss: 1.3130 - val_accuracy: 0.6580\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.6204 - accuracy: 0.7792 - val_loss: 1.2398 - val_accuracy: 0.6361\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5762 - accuracy: 0.8091 - val_loss: 1.3097 - val_accuracy: 0.6594\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4997 - accuracy: 0.8250 - val_loss: 1.3758 - val_accuracy: 0.6635\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4761 - accuracy: 0.8353 - val_loss: 1.4112 - val_accuracy: 0.6566\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.4588 - accuracy: 0.8405 - val_loss: 1.3974 - val_accuracy: 0.6703\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4542 - accuracy: 0.8456 - val_loss: 1.6053 - val_accuracy: 0.6635\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.4379 - accuracy: 0.8410 - val_loss: 1.5336 - val_accuracy: 0.6594\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4267 - accuracy: 0.8538 - val_loss: 1.5382 - val_accuracy: 0.6731\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4397 - accuracy: 0.8446 - val_loss: 1.4990 - val_accuracy: 0.6457\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4092 - accuracy: 0.8549 - val_loss: 1.5613 - val_accuracy: 0.6621\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.4207 - accuracy: 0.8513 - val_loss: 1.6336 - val_accuracy: 0.6635\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4008 - accuracy: 0.8564 - val_loss: 1.5492 - val_accuracy: 0.6813\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3854 - accuracy: 0.8652 - val_loss: 1.5832 - val_accuracy: 0.6607\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3663 - accuracy: 0.8693 - val_loss: 1.6979 - val_accuracy: 0.6676\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3619 - accuracy: 0.8703 - val_loss: 1.7338 - val_accuracy: 0.6758\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3639 - accuracy: 0.8755 - val_loss: 1.7236 - val_accuracy: 0.6471\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3419 - accuracy: 0.8791 - val_loss: 1.7429 - val_accuracy: 0.6525\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3191 - accuracy: 0.8873 - val_loss: 1.9007 - val_accuracy: 0.6635\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3059 - accuracy: 0.8888 - val_loss: 1.8785 - val_accuracy: 0.6566\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3052 - accuracy: 0.8940 - val_loss: 1.9541 - val_accuracy: 0.6635\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.3178 - accuracy: 0.8857 - val_loss: 2.0797 - val_accuracy: 0.6772\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3251 - accuracy: 0.8806 - val_loss: 1.8069 - val_accuracy: 0.6389\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3101 - accuracy: 0.8996 - val_loss: 1.8897 - val_accuracy: 0.6525\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.2937 - accuracy: 0.8950 - val_loss: 1.9333 - val_accuracy: 0.6607\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2834 - accuracy: 0.8986 - val_loss: 1.8835 - val_accuracy: 0.6689\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.2751 - accuracy: 0.9038 - val_loss: 1.9842 - val_accuracy: 0.6621\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2758 - accuracy: 0.9084 - val_loss: 2.0432 - val_accuracy: 0.6635\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.2680 - accuracy: 0.9032 - val_loss: 2.0393 - val_accuracy: 0.6594\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2624 - accuracy: 0.9135 - val_loss: 2.0937 - val_accuracy: 0.6621\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2638 - accuracy: 0.9074 - val_loss: 2.1244 - val_accuracy: 0.6621\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2696 - accuracy: 0.9079 - val_loss: 2.1388 - val_accuracy: 0.6580\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2585 - accuracy: 0.9099 - val_loss: 2.1748 - val_accuracy: 0.6607\n",
      "\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 1.5492 - accuracy: 0.6813\n",
      "Training of model  8\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 2s 63ms/step - loss: 2.3624 - accuracy: 0.2702 - val_loss: 2.2330 - val_accuracy: 0.3470\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 2.0061 - accuracy: 0.3284 - val_loss: 2.0155 - val_accuracy: 0.3625\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.9222 - accuracy: 0.3644 - val_loss: 2.0526 - val_accuracy: 0.3893\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 2.0672 - accuracy: 0.3628 - val_loss: 2.0279 - val_accuracy: 0.3695\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.9081 - accuracy: 0.3706 - val_loss: 1.9362 - val_accuracy: 0.3695\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.8467 - accuracy: 0.3875 - val_loss: 1.8850 - val_accuracy: 0.4062\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.8196 - accuracy: 0.4014 - val_loss: 1.8383 - val_accuracy: 0.4203\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.7237 - accuracy: 0.4231 - val_loss: 1.7432 - val_accuracy: 0.4372\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.7183 - accuracy: 0.4231 - val_loss: 1.8012 - val_accuracy: 0.4372\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.6766 - accuracy: 0.4457 - val_loss: 1.8066 - val_accuracy: 0.4528\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.6398 - accuracy: 0.4308 - val_loss: 1.6757 - val_accuracy: 0.4556\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.6119 - accuracy: 0.4385 - val_loss: 1.6798 - val_accuracy: 0.4598\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.5221 - accuracy: 0.4812 - val_loss: 1.5766 - val_accuracy: 0.4965\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.4697 - accuracy: 0.5023 - val_loss: 1.5358 - val_accuracy: 0.4979\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 1.3655 - accuracy: 0.5389 - val_loss: 1.6603 - val_accuracy: 0.4654\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3017 - accuracy: 0.5615 - val_loss: 1.4560 - val_accuracy: 0.5331\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.2629 - accuracy: 0.5914 - val_loss: 1.6250 - val_accuracy: 0.5134\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.2999 - accuracy: 0.5625 - val_loss: 1.4723 - val_accuracy: 0.5698\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1662 - accuracy: 0.6243 - val_loss: 1.5490 - val_accuracy: 0.5162\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.2108 - accuracy: 0.5991 - val_loss: 1.3711 - val_accuracy: 0.6164\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.0801 - accuracy: 0.6552 - val_loss: 1.3995 - val_accuracy: 0.6107\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0524 - accuracy: 0.6583 - val_loss: 1.2528 - val_accuracy: 0.6135\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.9596 - accuracy: 0.6886 - val_loss: 1.3876 - val_accuracy: 0.6107\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.9320 - accuracy: 0.7010 - val_loss: 1.3949 - val_accuracy: 0.6403\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.1185 - accuracy: 0.6449 - val_loss: 1.4939 - val_accuracy: 0.5938\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.9312 - accuracy: 0.6979 - val_loss: 1.3012 - val_accuracy: 0.6192\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.9158 - accuracy: 0.7066 - val_loss: 1.3209 - val_accuracy: 0.6206\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.9429 - accuracy: 0.6953 - val_loss: 1.7094 - val_accuracy: 0.5712\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8695 - accuracy: 0.7061 - val_loss: 1.4876 - val_accuracy: 0.6262\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.8090 - accuracy: 0.7411 - val_loss: 1.3263 - val_accuracy: 0.6361\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.7512 - accuracy: 0.7530 - val_loss: 1.3444 - val_accuracy: 0.6403\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.7200 - accuracy: 0.7633 - val_loss: 1.4206 - val_accuracy: 0.6671\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.6708 - accuracy: 0.7756 - val_loss: 1.4146 - val_accuracy: 0.6587\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.6571 - accuracy: 0.7823 - val_loss: 1.2666 - val_accuracy: 0.6629\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.6511 - accuracy: 0.7792 - val_loss: 1.5049 - val_accuracy: 0.6530\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6968 - accuracy: 0.7699 - val_loss: 1.6621 - val_accuracy: 0.6291\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.6552 - accuracy: 0.7813 - val_loss: 1.6299 - val_accuracy: 0.6502\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.6300 - accuracy: 0.8013 - val_loss: 1.4051 - val_accuracy: 0.6305\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.5794 - accuracy: 0.8055 - val_loss: 1.5886 - val_accuracy: 0.6460\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.5298 - accuracy: 0.8163 - val_loss: 1.6708 - val_accuracy: 0.6657\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.5032 - accuracy: 0.8286 - val_loss: 1.7734 - val_accuracy: 0.6629\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5037 - accuracy: 0.8338 - val_loss: 1.6806 - val_accuracy: 0.6305\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5024 - accuracy: 0.8332 - val_loss: 1.5405 - val_accuracy: 0.6389\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 1s 46ms/step - loss: 0.4651 - accuracy: 0.8466 - val_loss: 1.7140 - val_accuracy: 0.6601\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4474 - accuracy: 0.8502 - val_loss: 1.8642 - val_accuracy: 0.6488\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4331 - accuracy: 0.8487 - val_loss: 1.8460 - val_accuracy: 0.6432\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4211 - accuracy: 0.8621 - val_loss: 1.9189 - val_accuracy: 0.6530\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4063 - accuracy: 0.8574 - val_loss: 1.9987 - val_accuracy: 0.6502\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4029 - accuracy: 0.8646 - val_loss: 1.9409 - val_accuracy: 0.6474\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3911 - accuracy: 0.8641 - val_loss: 1.9439 - val_accuracy: 0.6502\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3919 - accuracy: 0.8621 - val_loss: 1.9526 - val_accuracy: 0.6502\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3842 - accuracy: 0.8657 - val_loss: 2.0635 - val_accuracy: 0.6516\n",
      "\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.4206 - accuracy: 0.6671\n",
      "Training of model  9\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 2s 80ms/step - loss: 2.3966 - accuracy: 0.2985 - val_loss: 2.1602 - val_accuracy: 0.3441\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 2.0458 - accuracy: 0.3392 - val_loss: 1.9585 - val_accuracy: 0.3469\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.9969 - accuracy: 0.3489 - val_loss: 1.9528 - val_accuracy: 0.3581\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.9146 - accuracy: 0.3706 - val_loss: 2.0779 - val_accuracy: 0.3581\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.9039 - accuracy: 0.3829 - val_loss: 1.8558 - val_accuracy: 0.3933\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.8329 - accuracy: 0.3989 - val_loss: 1.8786 - val_accuracy: 0.4087\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.7664 - accuracy: 0.4076 - val_loss: 1.8452 - val_accuracy: 0.4410\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.7730 - accuracy: 0.4056 - val_loss: 1.7455 - val_accuracy: 0.4157\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.6771 - accuracy: 0.4318 - val_loss: 1.7073 - val_accuracy: 0.4537\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.5725 - accuracy: 0.4627 - val_loss: 1.6248 - val_accuracy: 0.4733\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.5417 - accuracy: 0.4730 - val_loss: 1.6879 - val_accuracy: 0.4607\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4888 - accuracy: 0.5136 - val_loss: 1.4852 - val_accuracy: 0.5014\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.5001 - accuracy: 0.5131 - val_loss: 1.4919 - val_accuracy: 0.4972\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3395 - accuracy: 0.5404 - val_loss: 1.5200 - val_accuracy: 0.5169\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3958 - accuracy: 0.5198 - val_loss: 1.4946 - val_accuracy: 0.5183\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3017 - accuracy: 0.5522 - val_loss: 1.4389 - val_accuracy: 0.5211\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.2424 - accuracy: 0.5811 - val_loss: 1.5158 - val_accuracy: 0.5197\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.2621 - accuracy: 0.5764 - val_loss: 1.3308 - val_accuracy: 0.5899\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.2261 - accuracy: 0.5924 - val_loss: 1.5445 - val_accuracy: 0.5323\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.1910 - accuracy: 0.6068 - val_loss: 1.3748 - val_accuracy: 0.6039\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.0552 - accuracy: 0.6490 - val_loss: 1.3432 - val_accuracy: 0.6194\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0428 - accuracy: 0.6490 - val_loss: 1.4390 - val_accuracy: 0.5843\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.9805 - accuracy: 0.6758 - val_loss: 1.4277 - val_accuracy: 0.6390\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0039 - accuracy: 0.6711 - val_loss: 1.4524 - val_accuracy: 0.5829\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.9781 - accuracy: 0.6814 - val_loss: 1.4845 - val_accuracy: 0.6025\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.9672 - accuracy: 0.6794 - val_loss: 1.3835 - val_accuracy: 0.6306\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.9403 - accuracy: 0.7041 - val_loss: 1.6579 - val_accuracy: 0.5716\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1750 - accuracy: 0.6294 - val_loss: 1.3432 - val_accuracy: 0.5801\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.0129 - accuracy: 0.6644 - val_loss: 1.2925 - val_accuracy: 0.6250\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.8569 - accuracy: 0.7097 - val_loss: 1.2856 - val_accuracy: 0.6419\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.7981 - accuracy: 0.7349 - val_loss: 1.2821 - val_accuracy: 0.6320\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.7637 - accuracy: 0.7370 - val_loss: 1.3805 - val_accuracy: 0.6348\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.7431 - accuracy: 0.7622 - val_loss: 1.3506 - val_accuracy: 0.6348\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6788 - accuracy: 0.7689 - val_loss: 1.5066 - val_accuracy: 0.6110\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.7357 - accuracy: 0.7530 - val_loss: 1.5046 - val_accuracy: 0.6362\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6655 - accuracy: 0.7787 - val_loss: 1.4946 - val_accuracy: 0.6390\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.6045 - accuracy: 0.7967 - val_loss: 1.3731 - val_accuracy: 0.6461\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.6117 - accuracy: 0.7952 - val_loss: 1.4409 - val_accuracy: 0.6461\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5917 - accuracy: 0.7936 - val_loss: 1.4304 - val_accuracy: 0.6559\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.5747 - accuracy: 0.8060 - val_loss: 1.5083 - val_accuracy: 0.6587\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.5579 - accuracy: 0.8060 - val_loss: 1.4892 - val_accuracy: 0.6601\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5324 - accuracy: 0.8183 - val_loss: 1.5392 - val_accuracy: 0.6517\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5190 - accuracy: 0.8209 - val_loss: 1.5197 - val_accuracy: 0.6419\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.5105 - accuracy: 0.8266 - val_loss: 1.6546 - val_accuracy: 0.6503\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4867 - accuracy: 0.8286 - val_loss: 1.7197 - val_accuracy: 0.6517\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.5232 - accuracy: 0.8230 - val_loss: 1.6753 - val_accuracy: 0.6250\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4940 - accuracy: 0.8291 - val_loss: 1.6885 - val_accuracy: 0.6419\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.4416 - accuracy: 0.8410 - val_loss: 1.7306 - val_accuracy: 0.6433\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4440 - accuracy: 0.8399 - val_loss: 1.7680 - val_accuracy: 0.6503\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.4348 - accuracy: 0.8482 - val_loss: 1.7619 - val_accuracy: 0.6306\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4231 - accuracy: 0.8549 - val_loss: 1.8417 - val_accuracy: 0.6517\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4119 - accuracy: 0.8502 - val_loss: 1.7550 - val_accuracy: 0.6531\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4069 - accuracy: 0.8518 - val_loss: 1.7370 - val_accuracy: 0.6447\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4140 - accuracy: 0.8554 - val_loss: 1.7487 - val_accuracy: 0.6419\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3998 - accuracy: 0.8533 - val_loss: 1.7916 - val_accuracy: 0.6419\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4012 - accuracy: 0.8600 - val_loss: 1.8124 - val_accuracy: 0.6447\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3858 - accuracy: 0.8554 - val_loss: 1.8384 - val_accuracy: 0.6489\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3776 - accuracy: 0.8652 - val_loss: 1.8459 - val_accuracy: 0.6545\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3778 - accuracy: 0.8646 - val_loss: 1.7785 - val_accuracy: 0.6559\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3831 - accuracy: 0.8626 - val_loss: 1.7760 - val_accuracy: 0.6404\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3842 - accuracy: 0.8600 - val_loss: 1.7841 - val_accuracy: 0.6503\n",
      "\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 1.4892 - accuracy: 0.6601\n",
      "Training of model  10\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 3s 80ms/step - loss: 2.4400 - accuracy: 0.3037 - val_loss: 2.2771 - val_accuracy: 0.3431\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 2.0523 - accuracy: 0.3592 - val_loss: 2.0544 - val_accuracy: 0.3598\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.9595 - accuracy: 0.3685 - val_loss: 1.9471 - val_accuracy: 0.3487\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.9000 - accuracy: 0.3803 - val_loss: 1.9944 - val_accuracy: 0.3766\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.8651 - accuracy: 0.4164 - val_loss: 1.8226 - val_accuracy: 0.3989\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 1.8185 - accuracy: 0.4066 - val_loss: 1.8392 - val_accuracy: 0.4017\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.7493 - accuracy: 0.4256 - val_loss: 1.8388 - val_accuracy: 0.4128\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.6142 - accuracy: 0.4555 - val_loss: 2.3746 - val_accuracy: 0.4100\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.6446 - accuracy: 0.4364 - val_loss: 1.9772 - val_accuracy: 0.4254\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.5641 - accuracy: 0.4683 - val_loss: 2.1538 - val_accuracy: 0.4212\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5324 - accuracy: 0.4714 - val_loss: 1.6190 - val_accuracy: 0.4505\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.4123 - accuracy: 0.5028 - val_loss: 1.6573 - val_accuracy: 0.4742\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.3898 - accuracy: 0.5306 - val_loss: 1.5587 - val_accuracy: 0.4616\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.2798 - accuracy: 0.5589 - val_loss: 1.6161 - val_accuracy: 0.5132\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.2485 - accuracy: 0.5857 - val_loss: 1.5340 - val_accuracy: 0.5662\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 1.1056 - accuracy: 0.6279 - val_loss: 1.4376 - val_accuracy: 0.5481\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1383 - accuracy: 0.6212 - val_loss: 1.4489 - val_accuracy: 0.5690\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0238 - accuracy: 0.6547 - val_loss: 1.3688 - val_accuracy: 0.5802\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.9405 - accuracy: 0.6855 - val_loss: 1.7343 - val_accuracy: 0.5802\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.9576 - accuracy: 0.6830 - val_loss: 1.3769 - val_accuracy: 0.5830\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.9067 - accuracy: 0.6933 - val_loss: 1.6869 - val_accuracy: 0.5844\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.8853 - accuracy: 0.7020 - val_loss: 1.4096 - val_accuracy: 0.5802\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8132 - accuracy: 0.7241 - val_loss: 1.6819 - val_accuracy: 0.5788\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8761 - accuracy: 0.7174 - val_loss: 1.4719 - val_accuracy: 0.5830\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.8561 - accuracy: 0.7159 - val_loss: 1.5756 - val_accuracy: 0.6025\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.8328 - accuracy: 0.7241 - val_loss: 1.7443 - val_accuracy: 0.5788\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.9214 - accuracy: 0.6943 - val_loss: 1.6543 - val_accuracy: 0.5844\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8410 - accuracy: 0.7293 - val_loss: 1.7284 - val_accuracy: 0.5621\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.7544 - accuracy: 0.7463 - val_loss: 1.8770 - val_accuracy: 0.5649\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.7415 - accuracy: 0.7509 - val_loss: 1.6405 - val_accuracy: 0.5900\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.6745 - accuracy: 0.7766 - val_loss: 1.9053 - val_accuracy: 0.6109\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6315 - accuracy: 0.7833 - val_loss: 1.8598 - val_accuracy: 0.5704\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5880 - accuracy: 0.7880 - val_loss: 2.1126 - val_accuracy: 0.6151\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5482 - accuracy: 0.8085 - val_loss: 2.0085 - val_accuracy: 0.6095\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5263 - accuracy: 0.8173 - val_loss: 2.0942 - val_accuracy: 0.6067\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5086 - accuracy: 0.8245 - val_loss: 2.1138 - val_accuracy: 0.6179\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5330 - accuracy: 0.8188 - val_loss: 2.1515 - val_accuracy: 0.5900\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4922 - accuracy: 0.8338 - val_loss: 2.1714 - val_accuracy: 0.6039\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4834 - accuracy: 0.8358 - val_loss: 2.0520 - val_accuracy: 0.6276\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4528 - accuracy: 0.8523 - val_loss: 2.5883 - val_accuracy: 0.6304\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4111 - accuracy: 0.8590 - val_loss: 2.5553 - val_accuracy: 0.6262\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.4045 - accuracy: 0.8569 - val_loss: 2.9206 - val_accuracy: 0.5941\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3849 - accuracy: 0.8708 - val_loss: 2.9241 - val_accuracy: 0.6151\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3927 - accuracy: 0.8667 - val_loss: 3.2281 - val_accuracy: 0.5983\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4577 - accuracy: 0.8471 - val_loss: 2.3602 - val_accuracy: 0.6248\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.3842 - accuracy: 0.8724 - val_loss: 2.5509 - val_accuracy: 0.5900\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3390 - accuracy: 0.8873 - val_loss: 2.9787 - val_accuracy: 0.6137\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3026 - accuracy: 0.9017 - val_loss: 3.0514 - val_accuracy: 0.5997\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2817 - accuracy: 0.9110 - val_loss: 3.1256 - val_accuracy: 0.6109\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.2732 - accuracy: 0.9110 - val_loss: 3.3020 - val_accuracy: 0.6081\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.2546 - accuracy: 0.9161 - val_loss: 3.2492 - val_accuracy: 0.6165\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2651 - accuracy: 0.9213 - val_loss: 3.4298 - val_accuracy: 0.6053\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.2378 - accuracy: 0.9259 - val_loss: 3.5694 - val_accuracy: 0.6109\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2485 - accuracy: 0.9285 - val_loss: 3.5760 - val_accuracy: 0.5997\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.2234 - accuracy: 0.9352 - val_loss: 3.5790 - val_accuracy: 0.6067\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2190 - accuracy: 0.9362 - val_loss: 3.5842 - val_accuracy: 0.6011\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.1986 - accuracy: 0.9475 - val_loss: 3.6889 - val_accuracy: 0.6039\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2124 - accuracy: 0.9398 - val_loss: 3.6879 - val_accuracy: 0.6053\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.1978 - accuracy: 0.9429 - val_loss: 3.8066 - val_accuracy: 0.6151\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1911 - accuracy: 0.9496 - val_loss: 3.8262 - val_accuracy: 0.5969\n",
      "\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 2.5883 - accuracy: 0.6304\n",
      "Training of model  11\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 2s 85ms/step - loss: 2.4011 - accuracy: 0.2084 - val_loss: 2.2306 - val_accuracy: 0.3236\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 2.1603 - accuracy: 0.3206 - val_loss: 2.0987 - val_accuracy: 0.3431\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 2.0503 - accuracy: 0.3381 - val_loss: 1.9977 - val_accuracy: 0.3444\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.9372 - accuracy: 0.3577 - val_loss: 1.9036 - val_accuracy: 0.3736\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.8819 - accuracy: 0.3824 - val_loss: 1.8292 - val_accuracy: 0.4056\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.8299 - accuracy: 0.3973 - val_loss: 1.8434 - val_accuracy: 0.3986\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.7485 - accuracy: 0.4128 - val_loss: 1.7428 - val_accuracy: 0.4250\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.6923 - accuracy: 0.4318 - val_loss: 1.7151 - val_accuracy: 0.4389\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.6495 - accuracy: 0.4297 - val_loss: 1.9177 - val_accuracy: 0.3708\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.8042 - accuracy: 0.4159 - val_loss: 1.7729 - val_accuracy: 0.4264\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.6392 - accuracy: 0.4534 - val_loss: 1.6811 - val_accuracy: 0.4431\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.7693 - accuracy: 0.4184 - val_loss: 1.7120 - val_accuracy: 0.4264\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.6016 - accuracy: 0.4611 - val_loss: 1.5754 - val_accuracy: 0.4792\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.5274 - accuracy: 0.4714 - val_loss: 1.5470 - val_accuracy: 0.4861\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.4472 - accuracy: 0.5080 - val_loss: 1.4982 - val_accuracy: 0.4889\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.6148 - accuracy: 0.4550 - val_loss: 1.5880 - val_accuracy: 0.4750\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5736 - accuracy: 0.4761 - val_loss: 1.5284 - val_accuracy: 0.4986\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.4343 - accuracy: 0.5152 - val_loss: 1.7833 - val_accuracy: 0.4792\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3702 - accuracy: 0.5229 - val_loss: 1.3861 - val_accuracy: 0.5208\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.2571 - accuracy: 0.5682 - val_loss: 1.3655 - val_accuracy: 0.5681\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.1928 - accuracy: 0.5955 - val_loss: 1.3990 - val_accuracy: 0.5583\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1039 - accuracy: 0.6289 - val_loss: 1.5476 - val_accuracy: 0.5431\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 1.2418 - accuracy: 0.5934 - val_loss: 1.5501 - val_accuracy: 0.5389\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1902 - accuracy: 0.6109 - val_loss: 1.3951 - val_accuracy: 0.5819\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.1627 - accuracy: 0.6305 - val_loss: 1.3825 - val_accuracy: 0.5750\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.2513 - accuracy: 0.6037 - val_loss: 1.4120 - val_accuracy: 0.5694\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.0911 - accuracy: 0.6402 - val_loss: 1.2398 - val_accuracy: 0.6000\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0373 - accuracy: 0.6824 - val_loss: 1.2425 - val_accuracy: 0.5944\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.9661 - accuracy: 0.6835 - val_loss: 1.2801 - val_accuracy: 0.6083\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.8777 - accuracy: 0.7036 - val_loss: 1.3361 - val_accuracy: 0.6111\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.8227 - accuracy: 0.7195 - val_loss: 1.4490 - val_accuracy: 0.5986\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8247 - accuracy: 0.7216 - val_loss: 1.4589 - val_accuracy: 0.5986\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8299 - accuracy: 0.7313 - val_loss: 1.2972 - val_accuracy: 0.6278\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.7920 - accuracy: 0.7380 - val_loss: 1.4533 - val_accuracy: 0.6208\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.6982 - accuracy: 0.7669 - val_loss: 1.6186 - val_accuracy: 0.6208\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.7307 - accuracy: 0.7535 - val_loss: 1.4174 - val_accuracy: 0.6194\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8227 - accuracy: 0.7344 - val_loss: 1.4980 - val_accuracy: 0.6000\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.8576 - accuracy: 0.7262 - val_loss: 1.5675 - val_accuracy: 0.6125\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.6653 - accuracy: 0.7705 - val_loss: 1.4444 - val_accuracy: 0.6250\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5913 - accuracy: 0.7859 - val_loss: 1.5919 - val_accuracy: 0.6472\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.5610 - accuracy: 0.8049 - val_loss: 1.6876 - val_accuracy: 0.6250\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5494 - accuracy: 0.8194 - val_loss: 1.7723 - val_accuracy: 0.6375\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5042 - accuracy: 0.8255 - val_loss: 1.9537 - val_accuracy: 0.6333\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4713 - accuracy: 0.8338 - val_loss: 1.8209 - val_accuracy: 0.6292\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4567 - accuracy: 0.8405 - val_loss: 2.0456 - val_accuracy: 0.6375\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4224 - accuracy: 0.8528 - val_loss: 2.0430 - val_accuracy: 0.6375\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4026 - accuracy: 0.8518 - val_loss: 2.1663 - val_accuracy: 0.6458\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3917 - accuracy: 0.8554 - val_loss: 2.3549 - val_accuracy: 0.6389\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3890 - accuracy: 0.8559 - val_loss: 2.2884 - val_accuracy: 0.6347\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3814 - accuracy: 0.8492 - val_loss: 2.1261 - val_accuracy: 0.6375\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.3709 - accuracy: 0.8564 - val_loss: 2.2684 - val_accuracy: 0.6292\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.3450 - accuracy: 0.8662 - val_loss: 2.3214 - val_accuracy: 0.6306\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3363 - accuracy: 0.8610 - val_loss: 2.3945 - val_accuracy: 0.6306\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3300 - accuracy: 0.8708 - val_loss: 2.3350 - val_accuracy: 0.6375\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3459 - accuracy: 0.8652 - val_loss: 2.4329 - val_accuracy: 0.6319\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3188 - accuracy: 0.8821 - val_loss: 2.5148 - val_accuracy: 0.6347\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3118 - accuracy: 0.8775 - val_loss: 2.5261 - val_accuracy: 0.6333\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3114 - accuracy: 0.8847 - val_loss: 2.5463 - val_accuracy: 0.6319\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.3050 - accuracy: 0.8780 - val_loss: 2.5444 - val_accuracy: 0.6361\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3065 - accuracy: 0.8780 - val_loss: 2.7048 - val_accuracy: 0.6375\n",
      "\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.5919 - accuracy: 0.6472\n",
      "Training of model  12\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 2s 58ms/step - loss: 2.4061 - accuracy: 0.3186 - val_loss: 2.0808 - val_accuracy: 0.3506\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 2.0167 - accuracy: 0.3423 - val_loss: 1.9945 - val_accuracy: 0.3492\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.9431 - accuracy: 0.3654 - val_loss: 1.9574 - val_accuracy: 0.3579\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.8678 - accuracy: 0.3839 - val_loss: 1.8720 - val_accuracy: 0.4214\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.7946 - accuracy: 0.4092 - val_loss: 1.7886 - val_accuracy: 0.4372\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.7208 - accuracy: 0.4159 - val_loss: 1.7928 - val_accuracy: 0.4170\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.7281 - accuracy: 0.4159 - val_loss: 1.7469 - val_accuracy: 0.4242\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.7396 - accuracy: 0.4128 - val_loss: 1.7333 - val_accuracy: 0.4286\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.6397 - accuracy: 0.4400 - val_loss: 1.7126 - val_accuracy: 0.4401\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.6359 - accuracy: 0.4308 - val_loss: 1.6291 - val_accuracy: 0.4488\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5431 - accuracy: 0.4581 - val_loss: 1.5504 - val_accuracy: 0.4560\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.5317 - accuracy: 0.4596 - val_loss: 1.5305 - val_accuracy: 0.4949\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4721 - accuracy: 0.4843 - val_loss: 1.7926 - val_accuracy: 0.4372\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4196 - accuracy: 0.4925 - val_loss: 1.3870 - val_accuracy: 0.5238\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.2601 - accuracy: 0.5641 - val_loss: 1.3860 - val_accuracy: 0.5325\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.2341 - accuracy: 0.5775 - val_loss: 1.4058 - val_accuracy: 0.5267\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.2352 - accuracy: 0.5919 - val_loss: 1.3659 - val_accuracy: 0.5584\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.1699 - accuracy: 0.6176 - val_loss: 1.2235 - val_accuracy: 0.6118\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.1699 - accuracy: 0.6320 - val_loss: 1.5771 - val_accuracy: 0.5512\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 1.1515 - accuracy: 0.6258 - val_loss: 1.2498 - val_accuracy: 0.5815\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0876 - accuracy: 0.6392 - val_loss: 1.3674 - val_accuracy: 0.5657\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.0221 - accuracy: 0.6799 - val_loss: 1.3684 - val_accuracy: 0.5714\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.9712 - accuracy: 0.6778 - val_loss: 1.3862 - val_accuracy: 0.5974\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.8987 - accuracy: 0.7056 - val_loss: 1.3664 - val_accuracy: 0.6032\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.8230 - accuracy: 0.7267 - val_loss: 1.4511 - val_accuracy: 0.6176\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.7791 - accuracy: 0.7416 - val_loss: 1.3591 - val_accuracy: 0.6190\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.7844 - accuracy: 0.7447 - val_loss: 1.3866 - val_accuracy: 0.6234\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.7364 - accuracy: 0.7591 - val_loss: 1.3499 - val_accuracy: 0.6306\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.6930 - accuracy: 0.7694 - val_loss: 1.3965 - val_accuracy: 0.6306\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.6840 - accuracy: 0.7710 - val_loss: 1.5907 - val_accuracy: 0.6162\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6519 - accuracy: 0.7756 - val_loss: 1.5380 - val_accuracy: 0.6277\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.7101 - accuracy: 0.7766 - val_loss: 1.6838 - val_accuracy: 0.6277\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.7402 - accuracy: 0.7607 - val_loss: 1.3720 - val_accuracy: 0.6147\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6619 - accuracy: 0.7751 - val_loss: 1.3875 - val_accuracy: 0.6205\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6046 - accuracy: 0.7998 - val_loss: 1.5375 - val_accuracy: 0.6291\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5577 - accuracy: 0.8121 - val_loss: 1.5343 - val_accuracy: 0.6219\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5445 - accuracy: 0.8188 - val_loss: 1.4306 - val_accuracy: 0.6104\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5265 - accuracy: 0.8235 - val_loss: 1.6253 - val_accuracy: 0.6248\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5011 - accuracy: 0.8410 - val_loss: 1.6453 - val_accuracy: 0.6248\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4828 - accuracy: 0.8379 - val_loss: 1.6515 - val_accuracy: 0.6219\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4654 - accuracy: 0.8518 - val_loss: 1.6892 - val_accuracy: 0.6176\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4584 - accuracy: 0.8528 - val_loss: 1.6924 - val_accuracy: 0.6364\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4506 - accuracy: 0.8523 - val_loss: 1.7266 - val_accuracy: 0.6205\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4319 - accuracy: 0.8595 - val_loss: 1.7948 - val_accuracy: 0.6147\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4427 - accuracy: 0.8513 - val_loss: 1.7782 - val_accuracy: 0.6306\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4207 - accuracy: 0.8657 - val_loss: 1.8613 - val_accuracy: 0.6234\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4117 - accuracy: 0.8672 - val_loss: 1.7923 - val_accuracy: 0.6104\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3978 - accuracy: 0.8744 - val_loss: 1.8726 - val_accuracy: 0.6190\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.3937 - accuracy: 0.8734 - val_loss: 1.8656 - val_accuracy: 0.6147\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.3840 - accuracy: 0.8801 - val_loss: 1.9034 - val_accuracy: 0.6147\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3834 - accuracy: 0.8770 - val_loss: 1.8905 - val_accuracy: 0.6219\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3914 - accuracy: 0.8703 - val_loss: 1.9100 - val_accuracy: 0.6219\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3700 - accuracy: 0.8852 - val_loss: 1.9252 - val_accuracy: 0.6176\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3619 - accuracy: 0.8852 - val_loss: 1.9335 - val_accuracy: 0.6176\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3587 - accuracy: 0.8893 - val_loss: 1.9450 - val_accuracy: 0.6118\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3525 - accuracy: 0.8904 - val_loss: 1.9678 - val_accuracy: 0.6162\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3544 - accuracy: 0.8837 - val_loss: 2.0508 - val_accuracy: 0.6263\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3589 - accuracy: 0.8852 - val_loss: 2.0282 - val_accuracy: 0.6205\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3336 - accuracy: 0.8929 - val_loss: 2.0581 - val_accuracy: 0.6248\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3454 - accuracy: 0.8935 - val_loss: 2.0354 - val_accuracy: 0.6118\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3393 - accuracy: 0.8955 - val_loss: 2.0633 - val_accuracy: 0.6176\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3461 - accuracy: 0.8883 - val_loss: 2.0651 - val_accuracy: 0.6205\n",
      "\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 1.6924 - accuracy: 0.6364\n",
      "Training of model  13\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 2s 59ms/step - loss: 2.4146 - accuracy: 0.3067 - val_loss: 1.9966 - val_accuracy: 0.3883\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 2.0378 - accuracy: 0.3335 - val_loss: 1.9021 - val_accuracy: 0.3826\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.9693 - accuracy: 0.3536 - val_loss: 1.8550 - val_accuracy: 0.4054\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.8841 - accuracy: 0.3773 - val_loss: 1.7636 - val_accuracy: 0.4410\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.8810 - accuracy: 0.3829 - val_loss: 1.7585 - val_accuracy: 0.4339\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.7965 - accuracy: 0.4009 - val_loss: 1.7101 - val_accuracy: 0.4623\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.7345 - accuracy: 0.4215 - val_loss: 1.6128 - val_accuracy: 0.4737\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.7341 - accuracy: 0.4195 - val_loss: 1.6107 - val_accuracy: 0.4822\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.6264 - accuracy: 0.4632 - val_loss: 1.5438 - val_accuracy: 0.5021\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5752 - accuracy: 0.4853 - val_loss: 1.8629 - val_accuracy: 0.4694\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.7902 - accuracy: 0.4395 - val_loss: 1.6521 - val_accuracy: 0.4780\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.6370 - accuracy: 0.4673 - val_loss: 1.5430 - val_accuracy: 0.5135\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5075 - accuracy: 0.5162 - val_loss: 1.5707 - val_accuracy: 0.5050\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 1.5659 - accuracy: 0.5111 - val_loss: 1.5492 - val_accuracy: 0.5078\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.4304 - accuracy: 0.5363 - val_loss: 1.4966 - val_accuracy: 0.5420\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.4763 - accuracy: 0.5239 - val_loss: 1.4088 - val_accuracy: 0.5235\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3641 - accuracy: 0.5672 - val_loss: 1.3537 - val_accuracy: 0.5676\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.2418 - accuracy: 0.6022 - val_loss: 1.7228 - val_accuracy: 0.5036\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.2665 - accuracy: 0.5898 - val_loss: 1.5732 - val_accuracy: 0.5405\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.2093 - accuracy: 0.6073 - val_loss: 1.3817 - val_accuracy: 0.5704\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.2134 - accuracy: 0.6083 - val_loss: 1.3105 - val_accuracy: 0.5846\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.1200 - accuracy: 0.6387 - val_loss: 1.3301 - val_accuracy: 0.6102\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0499 - accuracy: 0.6788 - val_loss: 1.3271 - val_accuracy: 0.6003\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.9879 - accuracy: 0.6897 - val_loss: 1.2665 - val_accuracy: 0.6245\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.9462 - accuracy: 0.7005 - val_loss: 1.4664 - val_accuracy: 0.5818\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.9535 - accuracy: 0.6958 - val_loss: 1.4158 - val_accuracy: 0.6358\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.9616 - accuracy: 0.6958 - val_loss: 1.3224 - val_accuracy: 0.6003\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.9086 - accuracy: 0.7133 - val_loss: 1.2007 - val_accuracy: 0.6444\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.8196 - accuracy: 0.7432 - val_loss: 1.3452 - val_accuracy: 0.6202\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.9121 - accuracy: 0.7159 - val_loss: 1.4789 - val_accuracy: 0.5989\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.8226 - accuracy: 0.7509 - val_loss: 1.4524 - val_accuracy: 0.6174\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.1031 - accuracy: 0.7118 - val_loss: 1.3937 - val_accuracy: 0.6145\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0495 - accuracy: 0.6866 - val_loss: 1.6501 - val_accuracy: 0.5889\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.1263 - accuracy: 0.6866 - val_loss: 1.1961 - val_accuracy: 0.6273\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.9207 - accuracy: 0.7066 - val_loss: 1.1741 - val_accuracy: 0.6287\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.7828 - accuracy: 0.7442 - val_loss: 1.2389 - val_accuracy: 0.6458\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.7281 - accuracy: 0.7663 - val_loss: 1.3843 - val_accuracy: 0.6344\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.7078 - accuracy: 0.7669 - val_loss: 1.4632 - val_accuracy: 0.6273\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.6709 - accuracy: 0.7849 - val_loss: 1.5156 - val_accuracy: 0.6330\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.6219 - accuracy: 0.7946 - val_loss: 1.4160 - val_accuracy: 0.6501\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5858 - accuracy: 0.7983 - val_loss: 1.7299 - val_accuracy: 0.6373\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5550 - accuracy: 0.8178 - val_loss: 1.6561 - val_accuracy: 0.6671\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.5642 - accuracy: 0.8121 - val_loss: 1.7193 - val_accuracy: 0.6444\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5468 - accuracy: 0.8199 - val_loss: 1.8738 - val_accuracy: 0.6373\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.5402 - accuracy: 0.8260 - val_loss: 2.1306 - val_accuracy: 0.6373\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.5206 - accuracy: 0.8286 - val_loss: 2.0685 - val_accuracy: 0.6444\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.4527 - accuracy: 0.8471 - val_loss: 2.0244 - val_accuracy: 0.6302\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4132 - accuracy: 0.8626 - val_loss: 2.0777 - val_accuracy: 0.6316\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3824 - accuracy: 0.8713 - val_loss: 2.2249 - val_accuracy: 0.6302\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3512 - accuracy: 0.8785 - val_loss: 2.3556 - val_accuracy: 0.6373\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3419 - accuracy: 0.8883 - val_loss: 2.5915 - val_accuracy: 0.6259\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3717 - accuracy: 0.8760 - val_loss: 2.5849 - val_accuracy: 0.6188\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3298 - accuracy: 0.8873 - val_loss: 2.5193 - val_accuracy: 0.6245\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3263 - accuracy: 0.8919 - val_loss: 2.6133 - val_accuracy: 0.6174\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3254 - accuracy: 0.8883 - val_loss: 2.6619 - val_accuracy: 0.6159\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3183 - accuracy: 0.8955 - val_loss: 2.2012 - val_accuracy: 0.6373\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.3010 - accuracy: 0.8996 - val_loss: 2.2992 - val_accuracy: 0.6131\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2885 - accuracy: 0.8976 - val_loss: 2.2842 - val_accuracy: 0.6202\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2724 - accuracy: 0.9094 - val_loss: 2.3366 - val_accuracy: 0.6302\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2590 - accuracy: 0.9161 - val_loss: 2.3561 - val_accuracy: 0.6216\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2588 - accuracy: 0.9141 - val_loss: 2.4603 - val_accuracy: 0.6287\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2764 - accuracy: 0.9104 - val_loss: 2.4612 - val_accuracy: 0.6316\n",
      "\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 1.6561 - accuracy: 0.6671\n",
      "Training of model  14\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 3s 82ms/step - loss: 2.4291 - accuracy: 0.2156 - val_loss: 2.2221 - val_accuracy: 0.3388\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 2.1746 - accuracy: 0.2928 - val_loss: 2.0297 - val_accuracy: 0.3567\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 2.0496 - accuracy: 0.3227 - val_loss: 1.9670 - val_accuracy: 0.3595\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 2.0014 - accuracy: 0.3314 - val_loss: 1.9078 - val_accuracy: 0.3857\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.9093 - accuracy: 0.3654 - val_loss: 1.8535 - val_accuracy: 0.3994\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.8697 - accuracy: 0.3700 - val_loss: 1.9574 - val_accuracy: 0.3802\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.9364 - accuracy: 0.3608 - val_loss: 1.9528 - val_accuracy: 0.4063\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.9345 - accuracy: 0.3773 - val_loss: 1.8072 - val_accuracy: 0.4242\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.7817 - accuracy: 0.3886 - val_loss: 1.7523 - val_accuracy: 0.4118\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.7474 - accuracy: 0.3922 - val_loss: 1.7134 - val_accuracy: 0.4229\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.6898 - accuracy: 0.4066 - val_loss: 1.7893 - val_accuracy: 0.4284\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.6651 - accuracy: 0.4169 - val_loss: 1.6525 - val_accuracy: 0.4587\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.7186 - accuracy: 0.4169 - val_loss: 1.8095 - val_accuracy: 0.4284\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.7242 - accuracy: 0.4256 - val_loss: 1.9037 - val_accuracy: 0.4408\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.6464 - accuracy: 0.4370 - val_loss: 1.6449 - val_accuracy: 0.4545\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5894 - accuracy: 0.4617 - val_loss: 1.6869 - val_accuracy: 0.4669\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.4909 - accuracy: 0.4864 - val_loss: 1.5752 - val_accuracy: 0.4986\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5527 - accuracy: 0.4730 - val_loss: 1.5249 - val_accuracy: 0.4656\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.4389 - accuracy: 0.5162 - val_loss: 1.4705 - val_accuracy: 0.5441\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.3718 - accuracy: 0.5327 - val_loss: 1.3486 - val_accuracy: 0.5675\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.2694 - accuracy: 0.5749 - val_loss: 1.3748 - val_accuracy: 0.5675\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.2900 - accuracy: 0.5831 - val_loss: 1.4611 - val_accuracy: 0.5730\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 1.1560 - accuracy: 0.6140 - val_loss: 1.4219 - val_accuracy: 0.5992\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.1220 - accuracy: 0.6161 - val_loss: 1.5631 - val_accuracy: 0.5785\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.0716 - accuracy: 0.6469 - val_loss: 1.6259 - val_accuracy: 0.5882\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.1164 - accuracy: 0.6186 - val_loss: 1.3715 - val_accuracy: 0.5716\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.0854 - accuracy: 0.6485 - val_loss: 1.5562 - val_accuracy: 0.6088\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0891 - accuracy: 0.6521 - val_loss: 1.4450 - val_accuracy: 0.5634\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.0365 - accuracy: 0.6536 - val_loss: 1.4030 - val_accuracy: 0.5895\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.0454 - accuracy: 0.6557 - val_loss: 1.5121 - val_accuracy: 0.5964\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.0136 - accuracy: 0.6644 - val_loss: 1.4427 - val_accuracy: 0.6322\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.9592 - accuracy: 0.6845 - val_loss: 1.2714 - val_accuracy: 0.5950\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8662 - accuracy: 0.7097 - val_loss: 1.3957 - val_accuracy: 0.6088\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.7764 - accuracy: 0.7391 - val_loss: 1.3904 - val_accuracy: 0.6185\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8083 - accuracy: 0.7272 - val_loss: 1.3071 - val_accuracy: 0.6322\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.7671 - accuracy: 0.7499 - val_loss: 1.9094 - val_accuracy: 0.6253\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.7725 - accuracy: 0.7504 - val_loss: 1.4061 - val_accuracy: 0.6295\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.6834 - accuracy: 0.7725 - val_loss: 1.6064 - val_accuracy: 0.6295\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6348 - accuracy: 0.7823 - val_loss: 1.7869 - val_accuracy: 0.6240\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.6291 - accuracy: 0.7828 - val_loss: 1.6473 - val_accuracy: 0.6281\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.6030 - accuracy: 0.7957 - val_loss: 1.8564 - val_accuracy: 0.6460\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5837 - accuracy: 0.8049 - val_loss: 2.1464 - val_accuracy: 0.6267\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.5600 - accuracy: 0.8106 - val_loss: 1.8475 - val_accuracy: 0.6253\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4981 - accuracy: 0.8276 - val_loss: 2.1500 - val_accuracy: 0.6556\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4981 - accuracy: 0.8348 - val_loss: 2.4224 - val_accuracy: 0.6295\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4952 - accuracy: 0.8224 - val_loss: 2.3617 - val_accuracy: 0.6419\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4860 - accuracy: 0.8327 - val_loss: 2.4776 - val_accuracy: 0.6405\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4842 - accuracy: 0.8296 - val_loss: 2.4134 - val_accuracy: 0.6433\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4181 - accuracy: 0.8564 - val_loss: 2.6467 - val_accuracy: 0.5909\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4309 - accuracy: 0.8518 - val_loss: 2.3261 - val_accuracy: 0.6350\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.4642 - accuracy: 0.8523 - val_loss: 3.6560 - val_accuracy: 0.6116\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.4279 - accuracy: 0.8585 - val_loss: 3.1170 - val_accuracy: 0.6460\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3604 - accuracy: 0.8718 - val_loss: 3.1447 - val_accuracy: 0.6405\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3799 - accuracy: 0.8739 - val_loss: 2.8108 - val_accuracy: 0.6157\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3087 - accuracy: 0.8960 - val_loss: 2.8984 - val_accuracy: 0.6405\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2988 - accuracy: 0.8996 - val_loss: 3.1489 - val_accuracy: 0.6253\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3048 - accuracy: 0.8991 - val_loss: 3.1407 - val_accuracy: 0.6281\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2831 - accuracy: 0.9079 - val_loss: 3.1912 - val_accuracy: 0.6295\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.2671 - accuracy: 0.9146 - val_loss: 3.1884 - val_accuracy: 0.6419\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2581 - accuracy: 0.9166 - val_loss: 3.0837 - val_accuracy: 0.6267\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.2421 - accuracy: 0.9264 - val_loss: 3.1724 - val_accuracy: 0.6240\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2526 - accuracy: 0.9223 - val_loss: 3.2866 - val_accuracy: 0.6322\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.2417 - accuracy: 0.9233 - val_loss: 3.3225 - val_accuracy: 0.6267\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.2372 - accuracy: 0.9238 - val_loss: 3.3610 - val_accuracy: 0.6309\n",
      "\n",
      "23/23 [==============================] - 0s 14ms/step - loss: 2.1500 - accuracy: 0.6556\n",
      "Training of model  15\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 2s 80ms/step - loss: 2.4363 - accuracy: 0.2795 - val_loss: 2.1987 - val_accuracy: 0.3635\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 2.0663 - accuracy: 0.3217 - val_loss: 1.9835 - val_accuracy: 0.3745\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.9582 - accuracy: 0.3453 - val_loss: 2.0175 - val_accuracy: 0.3951\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 1.9230 - accuracy: 0.3618 - val_loss: 1.8649 - val_accuracy: 0.4047\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.8812 - accuracy: 0.3752 - val_loss: 2.0771 - val_accuracy: 0.3333\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.9191 - accuracy: 0.3639 - val_loss: 1.7832 - val_accuracy: 0.4280\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.8097 - accuracy: 0.4107 - val_loss: 1.7362 - val_accuracy: 0.4609\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.7778 - accuracy: 0.4014 - val_loss: 1.7123 - val_accuracy: 0.4458\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.7196 - accuracy: 0.4215 - val_loss: 1.6311 - val_accuracy: 0.4829\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.7684 - accuracy: 0.4189 - val_loss: 1.8419 - val_accuracy: 0.4335\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.7967 - accuracy: 0.4050 - val_loss: 1.7268 - val_accuracy: 0.4774\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.6865 - accuracy: 0.4359 - val_loss: 1.7040 - val_accuracy: 0.4719\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.6085 - accuracy: 0.4653 - val_loss: 1.5846 - val_accuracy: 0.5034\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 1.5865 - accuracy: 0.4817 - val_loss: 1.4988 - val_accuracy: 0.5130\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.5212 - accuracy: 0.4977 - val_loss: 1.6547 - val_accuracy: 0.5226\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5644 - accuracy: 0.4894 - val_loss: 1.4717 - val_accuracy: 0.5391\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.5577 - accuracy: 0.4951 - val_loss: 1.4894 - val_accuracy: 0.5117\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.5528 - accuracy: 0.4694 - val_loss: 1.6860 - val_accuracy: 0.4883\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5201 - accuracy: 0.4931 - val_loss: 1.4024 - val_accuracy: 0.5830\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.3660 - accuracy: 0.5383 - val_loss: 1.3957 - val_accuracy: 0.5364\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.2773 - accuracy: 0.5630 - val_loss: 1.3169 - val_accuracy: 0.5898\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.2341 - accuracy: 0.5847 - val_loss: 1.3524 - val_accuracy: 0.5926\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.1907 - accuracy: 0.5970 - val_loss: 1.2452 - val_accuracy: 0.6324\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.1412 - accuracy: 0.6248 - val_loss: 1.2441 - val_accuracy: 0.6187\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1245 - accuracy: 0.6305 - val_loss: 1.2555 - val_accuracy: 0.6022\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.1072 - accuracy: 0.6402 - val_loss: 1.3178 - val_accuracy: 0.6214\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.1192 - accuracy: 0.6197 - val_loss: 1.3071 - val_accuracy: 0.6187\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0225 - accuracy: 0.6680 - val_loss: 1.3148 - val_accuracy: 0.6365\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0782 - accuracy: 0.6294 - val_loss: 1.3227 - val_accuracy: 0.6159\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.0874 - accuracy: 0.6392 - val_loss: 1.2898 - val_accuracy: 0.6283\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.9830 - accuracy: 0.6809 - val_loss: 1.2960 - val_accuracy: 0.6091\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.0132 - accuracy: 0.6680 - val_loss: 1.4640 - val_accuracy: 0.6091\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 1.1180 - accuracy: 0.6366 - val_loss: 1.3946 - val_accuracy: 0.5953\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.9617 - accuracy: 0.6577 - val_loss: 1.3711 - val_accuracy: 0.6296\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.8941 - accuracy: 0.7005 - val_loss: 1.2953 - val_accuracy: 0.6269\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8644 - accuracy: 0.7056 - val_loss: 1.2960 - val_accuracy: 0.6447\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.8196 - accuracy: 0.7159 - val_loss: 1.2861 - val_accuracy: 0.6516\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.7790 - accuracy: 0.7339 - val_loss: 1.3466 - val_accuracy: 0.6516\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.7591 - accuracy: 0.7458 - val_loss: 1.3378 - val_accuracy: 0.6612\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.7283 - accuracy: 0.7581 - val_loss: 1.3249 - val_accuracy: 0.6118\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.7246 - accuracy: 0.7530 - val_loss: 1.5675 - val_accuracy: 0.6475\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.7288 - accuracy: 0.7581 - val_loss: 1.4093 - val_accuracy: 0.6433\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.7315 - accuracy: 0.7555 - val_loss: 1.4637 - val_accuracy: 0.6516\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.7390 - accuracy: 0.7581 - val_loss: 1.5512 - val_accuracy: 0.6324\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6482 - accuracy: 0.7720 - val_loss: 1.5030 - val_accuracy: 0.6502\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.6127 - accuracy: 0.7880 - val_loss: 1.6628 - val_accuracy: 0.6365\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5891 - accuracy: 0.7941 - val_loss: 1.7037 - val_accuracy: 0.6420\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5839 - accuracy: 0.8049 - val_loss: 1.6342 - val_accuracy: 0.6447\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.5620 - accuracy: 0.8029 - val_loss: 1.6785 - val_accuracy: 0.6420\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.5336 - accuracy: 0.8111 - val_loss: 1.6895 - val_accuracy: 0.6433\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.5260 - accuracy: 0.8245 - val_loss: 1.7641 - val_accuracy: 0.6516\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5147 - accuracy: 0.8240 - val_loss: 1.7393 - val_accuracy: 0.6488\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5017 - accuracy: 0.8296 - val_loss: 1.7476 - val_accuracy: 0.6529\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4972 - accuracy: 0.8286 - val_loss: 1.8050 - val_accuracy: 0.6488\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.4906 - accuracy: 0.8276 - val_loss: 1.7550 - val_accuracy: 0.6584\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4804 - accuracy: 0.8322 - val_loss: 1.8370 - val_accuracy: 0.6337\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4826 - accuracy: 0.8343 - val_loss: 1.8368 - val_accuracy: 0.6379\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4797 - accuracy: 0.8332 - val_loss: 1.8028 - val_accuracy: 0.6543\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4672 - accuracy: 0.8384 - val_loss: 1.8471 - val_accuracy: 0.6488\n",
      "\n",
      "23/23 [==============================] - 0s 12ms/step - loss: 1.3378 - accuracy: 0.6612\n",
      "Training of model  16\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 2s 41ms/step - loss: 2.4513 - accuracy: 0.2383 - val_loss: 2.3688 - val_accuracy: 0.3679\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 2.1724 - accuracy: 0.2877 - val_loss: 2.0168 - val_accuracy: 0.3416\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.9859 - accuracy: 0.3536 - val_loss: 1.9401 - val_accuracy: 0.3541\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 1.8924 - accuracy: 0.3783 - val_loss: 1.8350 - val_accuracy: 0.4122\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.8824 - accuracy: 0.3942 - val_loss: 1.8850 - val_accuracy: 0.3928\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.7917 - accuracy: 0.4297 - val_loss: 1.7762 - val_accuracy: 0.4191\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.7155 - accuracy: 0.4303 - val_loss: 1.8926 - val_accuracy: 0.4080\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.6744 - accuracy: 0.4575 - val_loss: 1.7897 - val_accuracy: 0.4481\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.6810 - accuracy: 0.4375 - val_loss: 1.6968 - val_accuracy: 0.4343\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.6063 - accuracy: 0.4694 - val_loss: 1.6370 - val_accuracy: 0.4564\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5815 - accuracy: 0.4766 - val_loss: 1.6570 - val_accuracy: 0.4675\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4837 - accuracy: 0.5039 - val_loss: 1.6636 - val_accuracy: 0.4288\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.5174 - accuracy: 0.5033 - val_loss: 1.5927 - val_accuracy: 0.5048\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.3484 - accuracy: 0.5558 - val_loss: 1.5493 - val_accuracy: 0.5325\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.2756 - accuracy: 0.5775 - val_loss: 1.4653 - val_accuracy: 0.5353\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.2901 - accuracy: 0.5805 - val_loss: 1.4751 - val_accuracy: 0.5353\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1853 - accuracy: 0.6253 - val_loss: 1.3636 - val_accuracy: 0.6155\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.1220 - accuracy: 0.6361 - val_loss: 1.4008 - val_accuracy: 0.5768\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.0713 - accuracy: 0.6583 - val_loss: 1.6853 - val_accuracy: 0.5284\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.0956 - accuracy: 0.6475 - val_loss: 1.4252 - val_accuracy: 0.5864\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.1281 - accuracy: 0.6418 - val_loss: 1.3677 - val_accuracy: 0.5519\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0469 - accuracy: 0.6727 - val_loss: 1.8077 - val_accuracy: 0.5394\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0687 - accuracy: 0.6541 - val_loss: 1.2761 - val_accuracy: 0.6210\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.9310 - accuracy: 0.6969 - val_loss: 1.2945 - val_accuracy: 0.6127\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.8834 - accuracy: 0.7164 - val_loss: 1.2354 - val_accuracy: 0.6418\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8203 - accuracy: 0.7396 - val_loss: 1.2435 - val_accuracy: 0.6445\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.7889 - accuracy: 0.7483 - val_loss: 1.2772 - val_accuracy: 0.6335\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.7713 - accuracy: 0.7545 - val_loss: 1.3237 - val_accuracy: 0.6445\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.7430 - accuracy: 0.7627 - val_loss: 1.4428 - val_accuracy: 0.6404\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.6891 - accuracy: 0.7715 - val_loss: 1.4570 - val_accuracy: 0.6376\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.6935 - accuracy: 0.7741 - val_loss: 1.4969 - val_accuracy: 0.6459\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.7227 - accuracy: 0.7694 - val_loss: 1.4907 - val_accuracy: 0.6349\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.7017 - accuracy: 0.7828 - val_loss: 1.4916 - val_accuracy: 0.6349\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.7876 - accuracy: 0.7411 - val_loss: 1.4120 - val_accuracy: 0.6252\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.7240 - accuracy: 0.7617 - val_loss: 1.4661 - val_accuracy: 0.6155\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.6765 - accuracy: 0.7880 - val_loss: 1.4726 - val_accuracy: 0.6445\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6033 - accuracy: 0.8044 - val_loss: 1.4065 - val_accuracy: 0.6611\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5568 - accuracy: 0.8255 - val_loss: 1.4940 - val_accuracy: 0.6570\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.5476 - accuracy: 0.8235 - val_loss: 1.4690 - val_accuracy: 0.6584\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.5524 - accuracy: 0.8230 - val_loss: 1.5958 - val_accuracy: 0.6584\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5477 - accuracy: 0.8209 - val_loss: 1.5258 - val_accuracy: 0.6459\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.5489 - accuracy: 0.8250 - val_loss: 1.6435 - val_accuracy: 0.6598\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5286 - accuracy: 0.8312 - val_loss: 1.6749 - val_accuracy: 0.6556\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4806 - accuracy: 0.8441 - val_loss: 1.5379 - val_accuracy: 0.6611\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.4748 - accuracy: 0.8456 - val_loss: 1.6722 - val_accuracy: 0.6598\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4589 - accuracy: 0.8430 - val_loss: 1.6281 - val_accuracy: 0.6556\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4565 - accuracy: 0.8518 - val_loss: 1.7141 - val_accuracy: 0.6487\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4451 - accuracy: 0.8528 - val_loss: 1.7447 - val_accuracy: 0.6680\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4378 - accuracy: 0.8590 - val_loss: 1.7230 - val_accuracy: 0.6639\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4343 - accuracy: 0.8543 - val_loss: 1.7447 - val_accuracy: 0.6611\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4273 - accuracy: 0.8667 - val_loss: 1.8002 - val_accuracy: 0.6542\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4226 - accuracy: 0.8595 - val_loss: 1.8119 - val_accuracy: 0.6432\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4157 - accuracy: 0.8605 - val_loss: 1.7879 - val_accuracy: 0.6515\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4187 - accuracy: 0.8585 - val_loss: 1.8112 - val_accuracy: 0.6528\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.4099 - accuracy: 0.8636 - val_loss: 1.8203 - val_accuracy: 0.6556\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4096 - accuracy: 0.8621 - val_loss: 1.7994 - val_accuracy: 0.6584\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4059 - accuracy: 0.8646 - val_loss: 1.8249 - val_accuracy: 0.6611\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4054 - accuracy: 0.8616 - val_loss: 1.7852 - val_accuracy: 0.6708\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3993 - accuracy: 0.8708 - val_loss: 1.7808 - val_accuracy: 0.6556\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.4234 - accuracy: 0.8667 - val_loss: 1.8229 - val_accuracy: 0.6777\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.4015 - accuracy: 0.8657 - val_loss: 1.7838 - val_accuracy: 0.6708\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3957 - accuracy: 0.8698 - val_loss: 1.8538 - val_accuracy: 0.6625\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3828 - accuracy: 0.8682 - val_loss: 1.9012 - val_accuracy: 0.6611\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3969 - accuracy: 0.8631 - val_loss: 1.9102 - val_accuracy: 0.6570\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.3858 - accuracy: 0.8672 - val_loss: 1.9130 - val_accuracy: 0.6598\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3807 - accuracy: 0.8682 - val_loss: 1.8842 - val_accuracy: 0.6570\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3836 - accuracy: 0.8698 - val_loss: 1.9186 - val_accuracy: 0.6625\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3861 - accuracy: 0.8682 - val_loss: 1.9450 - val_accuracy: 0.6625\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3758 - accuracy: 0.8739 - val_loss: 1.9422 - val_accuracy: 0.6611\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3852 - accuracy: 0.8621 - val_loss: 1.8826 - val_accuracy: 0.6542\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3782 - accuracy: 0.8672 - val_loss: 1.8923 - val_accuracy: 0.6584\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3750 - accuracy: 0.8708 - val_loss: 1.8977 - val_accuracy: 0.6598\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3768 - accuracy: 0.8693 - val_loss: 1.9117 - val_accuracy: 0.6598\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3805 - accuracy: 0.8780 - val_loss: 1.9250 - val_accuracy: 0.6584\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3709 - accuracy: 0.8729 - val_loss: 1.9342 - val_accuracy: 0.6556\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3709 - accuracy: 0.8755 - val_loss: 1.9409 - val_accuracy: 0.6570\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3710 - accuracy: 0.8657 - val_loss: 1.9409 - val_accuracy: 0.6598\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3750 - accuracy: 0.8744 - val_loss: 1.9239 - val_accuracy: 0.6556\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3620 - accuracy: 0.8739 - val_loss: 1.9345 - val_accuracy: 0.6584\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3784 - accuracy: 0.8724 - val_loss: 1.9386 - val_accuracy: 0.6611\n",
      "\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 1.8229 - accuracy: 0.6777\n",
      "Training of model  17\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 3s 87ms/step - loss: 2.4148 - accuracy: 0.3037 - val_loss: 2.2263 - val_accuracy: 0.3645\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 2.1076 - accuracy: 0.3361 - val_loss: 1.9146 - val_accuracy: 0.3687\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.9997 - accuracy: 0.3525 - val_loss: 1.8927 - val_accuracy: 0.3813\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.9285 - accuracy: 0.3520 - val_loss: 1.8690 - val_accuracy: 0.4190\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.9241 - accuracy: 0.4004 - val_loss: 1.8212 - val_accuracy: 0.4316\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.8959 - accuracy: 0.3911 - val_loss: 1.7931 - val_accuracy: 0.4176\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 1.8352 - accuracy: 0.3870 - val_loss: 1.6990 - val_accuracy: 0.4413\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.8166 - accuracy: 0.3978 - val_loss: 1.7374 - val_accuracy: 0.4567\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.7223 - accuracy: 0.4241 - val_loss: 1.6556 - val_accuracy: 0.4553\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.7240 - accuracy: 0.4323 - val_loss: 1.6429 - val_accuracy: 0.4525\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.6358 - accuracy: 0.4493 - val_loss: 1.6058 - val_accuracy: 0.4860\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.5448 - accuracy: 0.4853 - val_loss: 1.5567 - val_accuracy: 0.4944\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.5129 - accuracy: 0.4956 - val_loss: 1.5802 - val_accuracy: 0.4832\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.4965 - accuracy: 0.4858 - val_loss: 1.5396 - val_accuracy: 0.5209\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.4292 - accuracy: 0.5311 - val_loss: 1.4710 - val_accuracy: 0.5237\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.4670 - accuracy: 0.5152 - val_loss: 1.6014 - val_accuracy: 0.4846\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.4008 - accuracy: 0.5358 - val_loss: 1.6645 - val_accuracy: 0.5014\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5126 - accuracy: 0.5167 - val_loss: 1.6010 - val_accuracy: 0.5070\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.4472 - accuracy: 0.5409 - val_loss: 1.5311 - val_accuracy: 0.5391\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.3060 - accuracy: 0.5677 - val_loss: 1.4933 - val_accuracy: 0.5209\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.2095 - accuracy: 0.6011 - val_loss: 1.5040 - val_accuracy: 0.5754\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.1749 - accuracy: 0.6119 - val_loss: 1.6877 - val_accuracy: 0.5279\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.1357 - accuracy: 0.6248 - val_loss: 1.3126 - val_accuracy: 0.5824\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1664 - accuracy: 0.6135 - val_loss: 1.4146 - val_accuracy: 0.5782\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0757 - accuracy: 0.6567 - val_loss: 1.3497 - val_accuracy: 0.5684\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.0585 - accuracy: 0.6536 - val_loss: 1.3669 - val_accuracy: 0.5782\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1751 - accuracy: 0.6547 - val_loss: 1.3927 - val_accuracy: 0.5377\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0805 - accuracy: 0.6397 - val_loss: 1.3346 - val_accuracy: 0.5950\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.9231 - accuracy: 0.7036 - val_loss: 1.2958 - val_accuracy: 0.6047\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.8593 - accuracy: 0.7200 - val_loss: 1.3439 - val_accuracy: 0.5880\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.9028 - accuracy: 0.6953 - val_loss: 1.5458 - val_accuracy: 0.6117\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8596 - accuracy: 0.7190 - val_loss: 1.5258 - val_accuracy: 0.5852\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.8493 - accuracy: 0.7272 - val_loss: 1.5263 - val_accuracy: 0.5405\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.8207 - accuracy: 0.7195 - val_loss: 1.3750 - val_accuracy: 0.5992\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.7321 - accuracy: 0.7545 - val_loss: 1.4935 - val_accuracy: 0.5992\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.7016 - accuracy: 0.7663 - val_loss: 1.4671 - val_accuracy: 0.6271\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.7105 - accuracy: 0.7679 - val_loss: 1.4316 - val_accuracy: 0.6006\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6619 - accuracy: 0.7854 - val_loss: 1.4088 - val_accuracy: 0.5992\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.6561 - accuracy: 0.7859 - val_loss: 1.4808 - val_accuracy: 0.6313\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.7037 - accuracy: 0.7669 - val_loss: 1.6249 - val_accuracy: 0.5740\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.0220 - accuracy: 0.6778 - val_loss: 1.7434 - val_accuracy: 0.5587\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.0248 - accuracy: 0.7015 - val_loss: 1.3006 - val_accuracy: 0.6047\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.8575 - accuracy: 0.7236 - val_loss: 1.3932 - val_accuracy: 0.5712\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.7190 - accuracy: 0.7581 - val_loss: 1.6007 - val_accuracy: 0.5740\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.6095 - accuracy: 0.7957 - val_loss: 1.5123 - val_accuracy: 0.6089\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5575 - accuracy: 0.8132 - val_loss: 1.5661 - val_accuracy: 0.6145\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.5108 - accuracy: 0.8142 - val_loss: 1.6133 - val_accuracy: 0.6145\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4649 - accuracy: 0.8451 - val_loss: 1.6822 - val_accuracy: 0.6061\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4318 - accuracy: 0.8585 - val_loss: 1.8461 - val_accuracy: 0.6355\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4239 - accuracy: 0.8600 - val_loss: 1.7920 - val_accuracy: 0.6327\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4116 - accuracy: 0.8605 - val_loss: 1.8828 - val_accuracy: 0.6327\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4610 - accuracy: 0.8430 - val_loss: 1.7417 - val_accuracy: 0.6159\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3766 - accuracy: 0.8729 - val_loss: 1.9089 - val_accuracy: 0.6229\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3746 - accuracy: 0.8672 - val_loss: 2.0514 - val_accuracy: 0.5852\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3332 - accuracy: 0.8883 - val_loss: 1.9403 - val_accuracy: 0.6103\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3088 - accuracy: 0.8981 - val_loss: 2.0470 - val_accuracy: 0.6299\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2837 - accuracy: 0.9043 - val_loss: 2.1603 - val_accuracy: 0.6369\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2697 - accuracy: 0.9151 - val_loss: 2.1382 - val_accuracy: 0.6229\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2600 - accuracy: 0.9171 - val_loss: 2.2744 - val_accuracy: 0.6145\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2465 - accuracy: 0.9197 - val_loss: 2.3740 - val_accuracy: 0.6271\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.2373 - accuracy: 0.9279 - val_loss: 2.3939 - val_accuracy: 0.6271\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2212 - accuracy: 0.9346 - val_loss: 2.4702 - val_accuracy: 0.6117\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1981 - accuracy: 0.9434 - val_loss: 2.5799 - val_accuracy: 0.6285\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 30ms/step - loss: 0.2009 - accuracy: 0.9388 - val_loss: 2.4962 - val_accuracy: 0.6215\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.1987 - accuracy: 0.9393 - val_loss: 2.6340 - val_accuracy: 0.6145\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1926 - accuracy: 0.9403 - val_loss: 2.5352 - val_accuracy: 0.6131\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2008 - accuracy: 0.9429 - val_loss: 2.6348 - val_accuracy: 0.6089\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.1941 - accuracy: 0.9490 - val_loss: 2.5714 - val_accuracy: 0.6159\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1663 - accuracy: 0.9542 - val_loss: 2.5808 - val_accuracy: 0.6271\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1468 - accuracy: 0.9614 - val_loss: 2.6362 - val_accuracy: 0.6159\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1559 - accuracy: 0.9568 - val_loss: 2.7107 - val_accuracy: 0.6271\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.1541 - accuracy: 0.9583 - val_loss: 2.7327 - val_accuracy: 0.6215\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.1542 - accuracy: 0.9588 - val_loss: 2.7286 - val_accuracy: 0.6131\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.1523 - accuracy: 0.9532 - val_loss: 2.7432 - val_accuracy: 0.6159\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.1565 - accuracy: 0.9552 - val_loss: 2.7390 - val_accuracy: 0.6131\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1394 - accuracy: 0.9655 - val_loss: 2.7452 - val_accuracy: 0.6103\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.1468 - accuracy: 0.9593 - val_loss: 2.7654 - val_accuracy: 0.6131\n",
      "\n",
      "23/23 [==============================] - 0s 11ms/step - loss: 2.1603 - accuracy: 0.6369\n",
      "Training of model  18\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 2s 79ms/step - loss: 2.4219 - accuracy: 0.2753 - val_loss: 2.2005 - val_accuracy: 0.3338\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 2.0828 - accuracy: 0.3520 - val_loss: 2.0229 - val_accuracy: 0.3492\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.9727 - accuracy: 0.3536 - val_loss: 1.9975 - val_accuracy: 0.3506\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.9602 - accuracy: 0.3700 - val_loss: 1.9274 - val_accuracy: 0.3871\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.9264 - accuracy: 0.3767 - val_loss: 1.8508 - val_accuracy: 0.3913\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.8166 - accuracy: 0.4004 - val_loss: 1.7407 - val_accuracy: 0.4011\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.7975 - accuracy: 0.4164 - val_loss: 1.7420 - val_accuracy: 0.4137\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.8308 - accuracy: 0.4040 - val_loss: 1.8966 - val_accuracy: 0.3857\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.7830 - accuracy: 0.4138 - val_loss: 1.6885 - val_accuracy: 0.4151\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.6932 - accuracy: 0.4426 - val_loss: 2.4786 - val_accuracy: 0.2328\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.8395 - accuracy: 0.4143 - val_loss: 1.6568 - val_accuracy: 0.4502\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.6117 - accuracy: 0.4642 - val_loss: 1.5882 - val_accuracy: 0.4825\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.6135 - accuracy: 0.4689 - val_loss: 1.7018 - val_accuracy: 0.4390\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 1.5290 - accuracy: 0.4848 - val_loss: 1.4847 - val_accuracy: 0.5119\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 1.4122 - accuracy: 0.5306 - val_loss: 1.4141 - val_accuracy: 0.5372\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.3824 - accuracy: 0.5399 - val_loss: 1.5139 - val_accuracy: 0.5049\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3678 - accuracy: 0.5553 - val_loss: 1.4491 - val_accuracy: 0.5470\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.2380 - accuracy: 0.5965 - val_loss: 1.3441 - val_accuracy: 0.5652\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1736 - accuracy: 0.6305 - val_loss: 1.3473 - val_accuracy: 0.5806\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.1183 - accuracy: 0.6284 - val_loss: 1.4311 - val_accuracy: 0.5470\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.0874 - accuracy: 0.6475 - val_loss: 1.3192 - val_accuracy: 0.5989\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.9975 - accuracy: 0.6716 - val_loss: 1.3741 - val_accuracy: 0.5891\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.9717 - accuracy: 0.6752 - val_loss: 1.3983 - val_accuracy: 0.5863\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.9635 - accuracy: 0.6881 - val_loss: 1.5525 - val_accuracy: 0.5624\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.9853 - accuracy: 0.6902 - val_loss: 1.3744 - val_accuracy: 0.5863\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.9213 - accuracy: 0.7015 - val_loss: 1.3929 - val_accuracy: 0.5947\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.8572 - accuracy: 0.7205 - val_loss: 1.3754 - val_accuracy: 0.6143\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.8246 - accuracy: 0.7344 - val_loss: 1.4265 - val_accuracy: 0.6017\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.8140 - accuracy: 0.7283 - val_loss: 1.3512 - val_accuracy: 0.6339\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.7287 - accuracy: 0.7627 - val_loss: 1.3752 - val_accuracy: 0.6297\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.6887 - accuracy: 0.7725 - val_loss: 1.4125 - val_accuracy: 0.6311\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6882 - accuracy: 0.7797 - val_loss: 1.7463 - val_accuracy: 0.5764\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.7584 - accuracy: 0.7478 - val_loss: 1.4070 - val_accuracy: 0.6143\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.6817 - accuracy: 0.7931 - val_loss: 1.4803 - val_accuracy: 0.6213\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.6234 - accuracy: 0.8055 - val_loss: 1.4554 - val_accuracy: 0.6325\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.5690 - accuracy: 0.8266 - val_loss: 1.5056 - val_accuracy: 0.6339\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.5389 - accuracy: 0.8245 - val_loss: 1.5901 - val_accuracy: 0.6325\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4967 - accuracy: 0.8430 - val_loss: 1.6609 - val_accuracy: 0.6424\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.5009 - accuracy: 0.8338 - val_loss: 1.8246 - val_accuracy: 0.6381\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4869 - accuracy: 0.8379 - val_loss: 1.8097 - val_accuracy: 0.6241\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4758 - accuracy: 0.8430 - val_loss: 1.8234 - val_accuracy: 0.6129\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4557 - accuracy: 0.8492 - val_loss: 1.8653 - val_accuracy: 0.6381\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.4363 - accuracy: 0.8600 - val_loss: 1.9024 - val_accuracy: 0.6255\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.4101 - accuracy: 0.8631 - val_loss: 1.9590 - val_accuracy: 0.6508\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4019 - accuracy: 0.8631 - val_loss: 1.9501 - val_accuracy: 0.6143\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3914 - accuracy: 0.8693 - val_loss: 1.9961 - val_accuracy: 0.6522\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3840 - accuracy: 0.8698 - val_loss: 1.9389 - val_accuracy: 0.6339\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3690 - accuracy: 0.8755 - val_loss: 2.0355 - val_accuracy: 0.6438\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3538 - accuracy: 0.8806 - val_loss: 2.1752 - val_accuracy: 0.6353\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3597 - accuracy: 0.8765 - val_loss: 2.1644 - val_accuracy: 0.6269\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3482 - accuracy: 0.8801 - val_loss: 2.1838 - val_accuracy: 0.6410\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3368 - accuracy: 0.8806 - val_loss: 2.1693 - val_accuracy: 0.6339\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3322 - accuracy: 0.8837 - val_loss: 2.2308 - val_accuracy: 0.6424\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3256 - accuracy: 0.8873 - val_loss: 2.2710 - val_accuracy: 0.6311\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.3160 - accuracy: 0.8904 - val_loss: 2.2664 - val_accuracy: 0.6452\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3176 - accuracy: 0.8899 - val_loss: 2.3049 - val_accuracy: 0.6424\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3086 - accuracy: 0.8909 - val_loss: 2.3217 - val_accuracy: 0.6522\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.2974 - accuracy: 0.9007 - val_loss: 2.2986 - val_accuracy: 0.6367\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2949 - accuracy: 0.9012 - val_loss: 2.3523 - val_accuracy: 0.6410\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.2910 - accuracy: 0.8996 - val_loss: 2.3699 - val_accuracy: 0.6367\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3036 - accuracy: 0.8960 - val_loss: 2.3213 - val_accuracy: 0.6157\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3130 - accuracy: 0.8899 - val_loss: 2.3520 - val_accuracy: 0.6367\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2962 - accuracy: 0.8955 - val_loss: 2.3585 - val_accuracy: 0.6381\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.2960 - accuracy: 0.8986 - val_loss: 2.3543 - val_accuracy: 0.6410\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2872 - accuracy: 0.8940 - val_loss: 2.3561 - val_accuracy: 0.6311\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.2865 - accuracy: 0.8986 - val_loss: 2.3905 - val_accuracy: 0.6410\n",
      "\n",
      "23/23 [==============================] - 0s 16ms/step - loss: 1.9961 - accuracy: 0.6522\n",
      "Training of model  19\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 2s 58ms/step - loss: 2.4552 - accuracy: 0.2403 - val_loss: 2.3026 - val_accuracy: 0.1697\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 2.0772 - accuracy: 0.3078 - val_loss: 1.9556 - val_accuracy: 0.3621\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.9646 - accuracy: 0.3634 - val_loss: 1.9022 - val_accuracy: 0.3720\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.8848 - accuracy: 0.3757 - val_loss: 1.8277 - val_accuracy: 0.3861\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.8312 - accuracy: 0.4097 - val_loss: 1.8033 - val_accuracy: 0.4116\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.8311 - accuracy: 0.4236 - val_loss: 1.7747 - val_accuracy: 0.4130\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.7556 - accuracy: 0.4297 - val_loss: 1.7457 - val_accuracy: 0.4130\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.7022 - accuracy: 0.4359 - val_loss: 1.7104 - val_accuracy: 0.4342\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.6451 - accuracy: 0.4545 - val_loss: 1.6384 - val_accuracy: 0.4710\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.5899 - accuracy: 0.4802 - val_loss: 1.6133 - val_accuracy: 0.4653\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.6123 - accuracy: 0.4761 - val_loss: 1.6583 - val_accuracy: 0.4554\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.6388 - accuracy: 0.4668 - val_loss: 1.6066 - val_accuracy: 0.4611\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 1.5823 - accuracy: 0.4843 - val_loss: 1.5845 - val_accuracy: 0.4908\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.5172 - accuracy: 0.5157 - val_loss: 1.4948 - val_accuracy: 0.4950\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3947 - accuracy: 0.5502 - val_loss: 1.3923 - val_accuracy: 0.5361\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3799 - accuracy: 0.5440 - val_loss: 1.5072 - val_accuracy: 0.5050\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3489 - accuracy: 0.5455 - val_loss: 1.4157 - val_accuracy: 0.5361\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.1989 - accuracy: 0.6001 - val_loss: 1.3450 - val_accuracy: 0.5446\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.1077 - accuracy: 0.6315 - val_loss: 1.3942 - val_accuracy: 0.5615\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3528 - accuracy: 0.5600 - val_loss: 1.4061 - val_accuracy: 0.5403\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.2669 - accuracy: 0.5975 - val_loss: 1.3992 - val_accuracy: 0.5516\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1416 - accuracy: 0.6438 - val_loss: 1.3542 - val_accuracy: 0.5530\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.3326 - accuracy: 0.5996 - val_loss: 1.8577 - val_accuracy: 0.4017\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.4936 - accuracy: 0.5322 - val_loss: 1.4379 - val_accuracy: 0.5347\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.2565 - accuracy: 0.5919 - val_loss: 1.4673 - val_accuracy: 0.5785\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 1.1184 - accuracy: 0.6330 - val_loss: 1.2404 - val_accuracy: 0.6054\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 1.0561 - accuracy: 0.6521 - val_loss: 1.2344 - val_accuracy: 0.6124\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.9805 - accuracy: 0.6809 - val_loss: 1.3167 - val_accuracy: 0.6195\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.9631 - accuracy: 0.6953 - val_loss: 1.2752 - val_accuracy: 0.6110\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.9163 - accuracy: 0.7005 - val_loss: 1.4137 - val_accuracy: 0.6082\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.9294 - accuracy: 0.7072 - val_loss: 1.3075 - val_accuracy: 0.6082\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.8846 - accuracy: 0.7113 - val_loss: 1.3468 - val_accuracy: 0.6337\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.8235 - accuracy: 0.7334 - val_loss: 1.2904 - val_accuracy: 0.6379\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.7989 - accuracy: 0.7391 - val_loss: 1.4487 - val_accuracy: 0.6068\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.7801 - accuracy: 0.7411 - val_loss: 1.3542 - val_accuracy: 0.6209\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.7529 - accuracy: 0.7560 - val_loss: 1.5428 - val_accuracy: 0.5926\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.9249 - accuracy: 0.7097 - val_loss: 1.2475 - val_accuracy: 0.6082\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.8320 - accuracy: 0.7216 - val_loss: 1.2416 - val_accuracy: 0.6337\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.7475 - accuracy: 0.7540 - val_loss: 1.2380 - val_accuracy: 0.6450\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.7007 - accuracy: 0.7684 - val_loss: 1.2560 - val_accuracy: 0.6506\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6592 - accuracy: 0.7771 - val_loss: 1.3427 - val_accuracy: 0.6563\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6451 - accuracy: 0.7756 - val_loss: 1.3143 - val_accuracy: 0.6464\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.6055 - accuracy: 0.7977 - val_loss: 1.2600 - val_accuracy: 0.6634\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5988 - accuracy: 0.8008 - val_loss: 1.3285 - val_accuracy: 0.6634\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5692 - accuracy: 0.8080 - val_loss: 1.3595 - val_accuracy: 0.6492\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.5767 - accuracy: 0.8039 - val_loss: 1.3381 - val_accuracy: 0.6238\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5283 - accuracy: 0.8111 - val_loss: 1.3606 - val_accuracy: 0.6436\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.5325 - accuracy: 0.8178 - val_loss: 1.5680 - val_accuracy: 0.6549\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5124 - accuracy: 0.8250 - val_loss: 1.5062 - val_accuracy: 0.6521\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.4669 - accuracy: 0.8348 - val_loss: 1.4780 - val_accuracy: 0.6591\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4487 - accuracy: 0.8384 - val_loss: 1.5145 - val_accuracy: 0.6591\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4334 - accuracy: 0.8466 - val_loss: 1.5455 - val_accuracy: 0.6563\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4265 - accuracy: 0.8533 - val_loss: 1.5998 - val_accuracy: 0.6506\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4104 - accuracy: 0.8543 - val_loss: 1.6120 - val_accuracy: 0.6450\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4092 - accuracy: 0.8580 - val_loss: 1.6191 - val_accuracy: 0.6648\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4069 - accuracy: 0.8626 - val_loss: 1.6196 - val_accuracy: 0.6506\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.3979 - accuracy: 0.8626 - val_loss: 1.6151 - val_accuracy: 0.6506\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4008 - accuracy: 0.8580 - val_loss: 1.6141 - val_accuracy: 0.6464\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3875 - accuracy: 0.8595 - val_loss: 1.6393 - val_accuracy: 0.6549\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3742 - accuracy: 0.8688 - val_loss: 1.6372 - val_accuracy: 0.6605\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3802 - accuracy: 0.8724 - val_loss: 1.6361 - val_accuracy: 0.6549\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3627 - accuracy: 0.8729 - val_loss: 1.6916 - val_accuracy: 0.6563\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3670 - accuracy: 0.8662 - val_loss: 1.6781 - val_accuracy: 0.6577\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3682 - accuracy: 0.8760 - val_loss: 1.6905 - val_accuracy: 0.6634\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3572 - accuracy: 0.8724 - val_loss: 1.7133 - val_accuracy: 0.6591\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3521 - accuracy: 0.8770 - val_loss: 1.7066 - val_accuracy: 0.6549\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3505 - accuracy: 0.8801 - val_loss: 1.7195 - val_accuracy: 0.6605\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3582 - accuracy: 0.8791 - val_loss: 1.7166 - val_accuracy: 0.6506\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3517 - accuracy: 0.8847 - val_loss: 1.7443 - val_accuracy: 0.6563\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.3512 - accuracy: 0.8785 - val_loss: 1.7435 - val_accuracy: 0.6549\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3449 - accuracy: 0.8760 - val_loss: 1.7479 - val_accuracy: 0.6535\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3435 - accuracy: 0.8837 - val_loss: 1.7445 - val_accuracy: 0.6535\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3535 - accuracy: 0.8796 - val_loss: 1.7404 - val_accuracy: 0.6549\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3551 - accuracy: 0.8785 - val_loss: 1.7517 - val_accuracy: 0.6535\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3384 - accuracy: 0.8796 - val_loss: 1.7526 - val_accuracy: 0.6535\n",
      "\n",
      "23/23 [==============================] - 0s 10ms/step - loss: 1.6191 - accuracy: 0.6648\n",
      "Validation scores for each model:\n",
      "Score of model  0\n",
      "[1.6190701723098755, 0.6647807359695435]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create folders and callbacks and fit\n",
    "cbs = create_folders_and_callbacks(model_name, experiments_name)\n",
    "cbs.append([tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=patience1, restore_best_weights=True),\n",
    "        tfk.callbacks.ReduceLROnPlateau(monitor='val_accuracy', mode='max', patience=patience_plateau, factor=lr_factor, min_lr=min_lr)])\n",
    "\n",
    "    \n",
    "if noise:\n",
    "    if not bagging:\n",
    "      ds = AWGNTrain(X_train, y_train, batch_size)\n",
    "\n",
    "      history = model.fit(\n",
    "          ds,\n",
    "          batch_size = batch_size,\n",
    "          epochs = epochs,\n",
    "          validation_data=(X_val, y_val),\n",
    "          callbacks = cbs,\n",
    "          shuffle = True\n",
    "      ).history\n",
    "  \n",
    "else:\n",
    "    if not bagging:\n",
    "      # Train the model\n",
    "      history = model.fit(\n",
    "          x = X_train,\n",
    "          y = y_train,\n",
    "          batch_size = batch_size,\n",
    "          epochs = epochs,\n",
    "          validation_data=(X_val, y_val),\n",
    "          callbacks = cbs,\n",
    "          shuffle = True\n",
    "      ).history\n",
    "    \n",
    "    else:\n",
    "        model.fit(\n",
    "          x = X_train,\n",
    "          y = y_train,\n",
    "          batch_size = batch_size,\n",
    "          epochs = epochs,\n",
    "          validation_data=(X_val, y_val),\n",
    "          callbacks = cbs,\n",
    "          shuffle = True\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e93de9a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T19:50:14.984068Z",
     "iopub.status.busy": "2022-12-17T19:50:14.983680Z",
     "iopub.status.idle": "2022-12-17T19:50:14.995558Z",
     "shell.execute_reply": "2022-12-17T19:50:14.994644Z"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "aborted",
     "timestamp": 1671270553512,
     "user": {
      "displayName": "Andrea Giuffrida",
      "userId": "01201743058689716524"
     },
     "user_tz": -60
    },
    "id": "jUUY4BTv2tfI",
    "papermill": {
     "duration": 0.491188,
     "end_time": "2022-12-17T19:50:14.997813",
     "exception": false,
     "start_time": "2022-12-17T19:50:14.506625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not bagging:\n",
    "    best_epoch = np.argmax(history['val_accuracy'])\n",
    "    plt.figure(figsize=(17,4))\n",
    "    plt.plot(history['loss'], label='Training loss', alpha=.8, color='#ff7f0e')\n",
    "    plt.plot(history['val_loss'], label='Validation loss', alpha=.9, color='#5a9aa5')\n",
    "    plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n",
    "    plt.title('Categorical Crossentropy')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=.3)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(17,4))\n",
    "    plt.plot(history['accuracy'], label='Training accuracy', alpha=.8, color='#ff7f0e')\n",
    "    plt.plot(history['val_accuracy'], label='Validation accuracy', alpha=.9, color='#5a9aa5')\n",
    "    plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=.3)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(17,4))\n",
    "    plt.plot(history['lr'], label='Learning Rate', alpha=.8, color='#ff7f0e')\n",
    "    plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41be97d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T19:50:15.938426Z",
     "iopub.status.busy": "2022-12-17T19:50:15.938000Z",
     "iopub.status.idle": "2022-12-17T19:50:21.748367Z",
     "shell.execute_reply": "2022-12-17T19:50:21.747417Z"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "aborted",
     "timestamp": 1671270553513,
     "user": {
      "displayName": "Andrea Giuffrida",
      "userId": "01201743058689716524"
     },
     "user_tz": -60
    },
    "id": "jB17zUlBBTY_",
    "papermill": {
     "duration": 6.286108,
     "end_time": "2022-12-17T19:50:21.751166",
     "exception": false,
     "start_time": "2022-12-17T19:50:15.465058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(486, 12)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the test set with the RNN\n",
    "predictions = model.predict(X_val)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f15e5656",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T19:50:22.826787Z",
     "iopub.status.busy": "2022-12-17T19:50:22.826429Z",
     "iopub.status.idle": "2022-12-17T19:50:22.832912Z",
     "shell.execute_reply": "2022-12-17T19:50:22.831900Z"
    },
    "papermill": {
     "duration": 0.479684,
     "end_time": "2022-12-17T19:50:22.835905",
     "exception": false,
     "start_time": "2022-12-17T19:50:22.356221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  1  9  9  9  8  9  9  3  1  9  6  6  6  2  9  1  3 10  6  9  2  9  3\n",
      "  9  9  6  9  3  3  9  9  8  1  9  9  9  6  2  1  9  3  9  1  9  9  2 10\n",
      "  9  2  9  9  8  6  8  9  9  6  6  9  8  3  1  2  9  9  2  3  9  3  2  6\n",
      "  9  9 11  9  9  2  3  6  9  3  8  9  2  6  9  2  9  6  9  6  9  1  3  9\n",
      "  9  2  6  2  9  9 10  3  2  9  9 10  6  9  9  9  6  8  6  9  3  6  9  9\n",
      "  6  6  0  6  3  9  6  2  9  3  6  9  3  9  6  9  2  9  3  9  6  9  6  9\n",
      "  9  8  9  2  9  2  8  9  9  3 10  2  9  9  3  2  8  0  6  9  9  9  6  2\n",
      "  2  9  9  9  3  6  9  2  9  2  9 10  3  2  9  9  3  5  3  6  9  9  6  9\n",
      "  5  3  3  9  3  0  8  3  9  0  9 10  9  5  3 11  2  1  8  6  2  9  3  6\n",
      "  2  8  9  2  8  6  3  9  6  2  1  9  9  2  2 10  9  1  0  9  3  2  9  5\n",
      "  6  3  9  3  6  9  9  6  3  3  6  3  9  6  9  9  9  9  9  9  9  2  9  9\n",
      "  9  9  9  1  6  6  9 10  9  1  6  2  9  2  3  9  9 10  6 10  6  3  9  6\n",
      "  6  6  9  9  6  1  3  9  9  9  3  9  1  0  8  3  3  9  6  9  9  9  9  2\n",
      "  5  3  9  6  9  9  9  3  3  3  9  5  2  9  9  1  3  3  6  6  9  1  9  3\n",
      "  9  5  3  9  9  3 10  2  9  9  9  3  9  3  9  3  9  2  9  9  8  2  3  9\n",
      "  0  9  3  9  2 10  9  3  9  3  9 10  3  5  2  3  3  2  3  3  9  3  8  9\n",
      "  9 10  5  2  6  3  6 10  3  9  6  9  9  1  0  6  9  8  9  6  9  3  9  9\n",
      "  6  9  3  3  2  9  3  6  1  2  9  9  8  2  9  9  9  3  9  3  6  5  9  9\n",
      "  2  2  9  9  5  9  3  9  5  6  9  9  2  2  2  3  9  9  3  9  9  1  6  9\n",
      "  6  8  2  9  6  6  9  1  2  2  9  9  9  2  2  2  9  9  6  2  9  3  9  9\n",
      "  2  9  8  3  9  9]\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(predictions, axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd39b240",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T19:50:23.816872Z",
     "iopub.status.busy": "2022-12-17T19:50:23.816497Z",
     "iopub.status.idle": "2022-12-17T19:50:24.659029Z",
     "shell.execute_reply": "2022-12-17T19:50:24.657999Z"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "aborted",
     "timestamp": 1671270553515,
     "user": {
      "displayName": "Andrea Giuffrida",
      "userId": "01201743058689716524"
     },
     "user_tz": -60
    },
    "id": "6IDTgQQLBeNN",
    "papermill": {
     "duration": 1.308768,
     "end_time": "2022-12-17T19:50:24.661599",
     "exception": false,
     "start_time": "2022-12-17T19:50:23.352831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6893\n",
      "Precision: 0.5621\n",
      "Recall: 0.5423\n",
      "F1: 0.5158\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(np.argmax(y_val, axis=-1), np.argmax(predictions, axis=-1))\n",
    "\n",
    "# Compute the classification metrics\n",
    "accuracy = accuracy_score(np.argmax(y_val, axis=-1), np.argmax(predictions, axis=-1))\n",
    "precision = precision_score(np.argmax(y_val, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
    "recall = recall_score(np.argmax(y_val, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
    "f1 = f1_score(np.argmax(y_val, axis=-1), np.argmax(predictions, axis=-1), average='macro')\n",
    "print('Accuracy:',accuracy.round(4))\n",
    "print('Precision:',precision.round(4))\n",
    "print('Recall:',recall.round(4))\n",
    "print('F1:',f1.round(4))\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(cm.T, cmap='Blues', xticklabels=list(label_mapping), yticklabels=list(label_mapping), annot=True)\n",
    "plt.xlabel('True labels')\n",
    "plt.ylabel('Predicted labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b195ed7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T19:50:25.589328Z",
     "iopub.status.busy": "2022-12-17T19:50:25.587475Z",
     "iopub.status.idle": "2022-12-17T19:50:25.817834Z",
     "shell.execute_reply": "2022-12-17T19:50:25.816881Z"
    },
    "executionInfo": {
     "elapsed": 41257,
     "status": "aborted",
     "timestamp": 1671270553515,
     "user": {
      "displayName": "Andrea Giuffrida",
      "userId": "01201743058689716524"
     },
     "user_tz": -60
    },
    "id": "GL4WLnUb1-6y",
    "papermill": {
     "duration": 0.695898,
     "end_time": "2022-12-17T19:50:25.820111",
     "exception": false,
     "start_time": "2022-12-17T19:50:25.124213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1512x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1s = f1_score(np.argmax(y_val, axis=-1), np.argmax(predictions, axis=-1), average=None)\n",
    "\n",
    "fig = plt.figure(figsize=(21, 5))\n",
    "plt.bar(np.arange(12), f1s, width=1, edgecolor=\"white\", tick_label=list(label_mapping))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a97787",
   "metadata": {
    "id": "THxvILUd735B",
    "papermill": {
     "duration": 0.460088,
     "end_time": "2022-12-17T19:50:26.789427",
     "exception": false,
     "start_time": "2022-12-17T19:50:26.329339",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "439184cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-17T19:50:27.769442Z",
     "iopub.status.busy": "2022-12-17T19:50:27.769033Z",
     "iopub.status.idle": "2022-12-17T19:51:29.661766Z",
     "shell.execute_reply": "2022-12-17T19:51:29.660734Z"
    },
    "executionInfo": {
     "elapsed": 41250,
     "status": "aborted",
     "timestamp": 1671270553516,
     "user": {
      "displayName": "Andrea Giuffrida",
      "userId": "01201743058689716524"
     },
     "user_tz": -60
    },
    "id": "RXzlj3V3BMSC",
    "papermill": {
     "duration": 62.413243,
     "end_time": "2022-12-17T19:51:29.664884",
     "exception": false,
     "start_time": "2022-12-17T19:50:27.251641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-17 19:50:28.651037: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "model.save(model_name)\n",
    "#model.load(model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1884.478444,
   "end_time": "2022-12-17T19:51:33.884023",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-17T19:20:09.405579",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
